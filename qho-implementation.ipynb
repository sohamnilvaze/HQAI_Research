{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport torch\nfrom sklearn.datasets import fetch_openml\nimport scipy\n\n# ----------------------------\n# Load MNIST from OpenML\n# ----------------------------\n# mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n\n# mnist_images = mnist.data.astype(np.float64)   # (70000, 784)\n# mnist_labels = mnist.target.astype(int)        # (70000,)\n\n# x_train = mnist_images[:60000]\n# y_train = mnist_labels[:60000]\n# x_test  = mnist_images[60000:60201]\n# y_test  = mnist_labels[60000:60201]\n\n#OR\n\nfrom tensorflow.keras.datasets import mnist\n\n# Load MNIST using Keras\nprint(\"Loading the MNIST dataset\")\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# # Reshape and convert to float64 for consistency\nx_train = x_train.reshape(-1, 784).astype(np.float64)\nx_test = x_test.reshape(-1, 784).astype(np.float64)\nprint(\"Train:\", x_train.shape, y_train.shape)\nprint(\"Test:\", x_test.shape, y_test.shape)\n\n# ----------------------------\n# Helper functions\n# ----------------------------\ndef separate_digits(images, labels):\n    \"\"\"Group images by digit label.\"\"\"\n    digit_image = {d: [] for d in range(10)}\n    for img, lbl in zip(images, labels):\n        digit_image[lbl].append(img)\n    return digit_image\n\ndef resize_images_batch(images, new_size=(8, 8), batch_size=500):\n    \"\"\"Resize a batch of flattened 28x28 images to new_size.\"\"\"\n    n = len(images)\n    resized = []\n    for i in range(0, n, batch_size):\n        batch = images[i:i+batch_size]\n        resized_batch = [resize(img.reshape(28,28), new_size).flatten() for img in batch]\n        resized.extend(resized_batch)\n    return np.array(resized)\n\ndef normalize_batch(images):\n    \"\"\"Normalize each image vector.\"\"\"\n    norms = np.linalg.norm(images, axis=1, keepdims=True)\n    return images / norms\n\n#Creating Hamiltonian using outer product method\ndef density_matrix_batch(images):\n    \"\"\"Convert vectors to density matrices.\"\"\"\n    return np.matmul(images[:,:,np.newaxis], images[:,np.newaxis,:])\n\n#Creating the Hamiltonian using H = A + A.T/2 method\ndef hamiltonian_symmetric_batch(images):\n  N,D = images.shape\n  H_list = []\n  for i in range(N):\n    a = images[i]\n    A = np.outer(a,np.ones(D))\n    H = (A + A.conj().T) / 2\n    H_list.append(H)\n\n  return np.array(H_list)\n\n#Creating the Hamiltonian using H = A @ A.T method\ndef hamiltonian_product_batch(images):\n  N , D = images.shape\n  H_list = []\n  for i in range(N):\n    a = images[i]\n    A = np.outer(a,np.ones(D))\n    H = A @ A.T\n    H_list.append(H)\n  return np.array(H_list)\n\nimport scipy.linalg\n#Creating thr Hamiltonian using H = -i * log(V) method\ndef hamiltonian_using_log(images):\n    # def make_unitary1(matrix):\n    #     U, _, Vh = torch.linalg.svd(matrix, full_matrices=False)\n    #     return U @ Vh\n    \n    # def make_unitary2(matrix):\n    #     matrix = matrix / (torch.linalg.norm(matrix) + 1e-12) #for -i log(V) case only\n    #     Q,R = torch.linalg.qr(matrix)\n    #     return Q\n            \n    # N , D = images.shape\n    # hamiltonians = np.zeros((N,D,D), dtype = np.complex128)\n    # for i in range(N):\n    #     image = images[i]\n    #     mat = np.diag(image)\n    #     mat_torch = torch.tensor(mat,dtype = torch.complex128)\n    #     U_torch = make_unitary2(mat_torch)\n    #     U_np = U_torch.detach().cpu().numpy()\n    #     H = -1j * scipy.linalg.logm(U_np)\n    #     H = (H + H.conj().T) / 2\n    #     hamiltonians[i] = H\n\n    # return hamiltonians\n    def _make_hermitian(M):\n        return 0.5 * (M + M.conj().transpose(-2,-1))\n\n    def _make_unitary(M):\n        H = _make_hermitian(M)\n        return torch.matrix_exp(-1j*H)\n\n    N,D = images.shape\n    hamiltonians = np.zeros((N,D,D),dtype = np.complex128)\n    for i in range(N):\n        image = images[i]\n        mat = np.diag(image)\n        mat_torch = torch.tensor(mat,dtype = torch.complex128)\n        H = _make_unitary(mat_torch)\n        hamiltonians[i] = H\n    return hamiltonians\n        \n\n    \n        \n\n# ----------------------------\n# Process training data\n# ----------------------------\ndigit_images_dict = separate_digits(x_train, y_train)\nresized_digit_images = {}\nnormalized_digit_images = {}\ndensity_matrices = {}\n\nfor digit, imgs in digit_images_dict.items():\n    imgs = np.array(imgs)\n    imgs_resized = resize_images_batch(imgs, new_size=(8,8), batch_size=500)\n    imgs_normalized = normalize_batch(imgs_resized)\n    print(f\"normalized_images shape:- {imgs_normalized.shape}\")\n    density1 = density_matrix_batch(imgs_normalized)\n    print(f\"shape 1:- {density1.shape}\")\n    #OR\n    #density2 = hamiltonian_symmetric_batch(imgs_normalized)\n    #print(f\"shape 2:- {density2.shape}\")\n    #OR\n    #density3 = hamiltonian_product_batch(imgs_normalized)\n    #print(f\"shape 3:- {density3.shape}\")\n    #OR\n    #density4 = hamiltonian_using_log(imgs_normalized)\n    #print(f\"shape 4:- {density4.shape}\")\n    density1 /= np.linalg.norm(density1, axis=(1,2), keepdims=True)\n    #density2 /= np.linalg.norm(density2, axis=(1,2), keepdims=True)\n    #density3 /= np.linalg.norm(density3, axis=(1,2), keepdims=True)\n    #density4 /= np.linalg.norm(density4, axis=(1,2), keepdims=True)\n    resized_digit_images[digit] = imgs_resized\n    normalized_digit_images[digit] = imgs_normalized\n    density_matrices[digit] = density1\n    #density_matrices[digit] = density2\n    #density_matrices[digit] = density3\n    #density_matrices[digit] = density4\n\ntrain_density_matrices = np.concatenate([density_matrices[d] for d in range(10)], axis=0)\ntrain_density_matrices_tensor = torch.tensor(train_density_matrices, dtype=torch.cfloat)\n\n# ----------------------------\n# Process test data\n# ----------------------------\ntest_images_resized = np.array([resize(img.reshape(28,28), (8,8)).flatten() for img in x_test])\ntest_normed = normalize_batch(test_images_resized)\ntest_density = density_matrix_batch(test_normed)\ntest_density /= np.linalg.norm(test_density, axis=(1,2), keepdims=True)\ntest_density_tensor = torch.tensor(test_density, dtype=torch.cfloat)\n\n# ----------------------------\n# Visualization example\n# ---------------------------\n\nfor digit in range(10):\n    images_to_plot = resized_digit_images[digit][:10]\n    plt.figure(figsize=(10,2))\n    for i in range(10):\n        plt.subplot(1, 10, i+1)\n        plt.imshow(images_to_plot[i].reshape(8,8), cmap='magma')\n        plt.title(f\"{digit}\")\n        plt.axis('off')\n    plt.show()\n\nnormalized_Hermitian_Digit_matrices = train_density_matrices_tensor\n# normalized_Hermitian_Digit_matrices = torch.tensor(train_subset,dtype = torch.cfloat)\nnormalized_hermitian_matrices_test_input = test_density_tensor\n# normalized_hermitian_matrices_test_input = torch.tensor(test_subset,dtype = torch.cfloat)\n\nprint(f\"normalized_Hermitian_Digit_matrices shape:- {normalized_Hermitian_Digit_matrices.shape}\")\nprint(f\"normalized_hermitian_matrices_test_input shape:- {normalized_hermitian_matrices_test_input.shape}\")\n# normalized_Hermitian_Digit_matrices_small = torch.tensor(train_subset_small,dtype = torch.cfloat)\n# normalized_hermitian_matrices_test_input_small = torch.tensor(test_subset_small,dtype = torch.cfloat)\n\n\nlabels = []\nfor i in range(10):\n    labels.append(i)\n\nprint(labels)\n\nD = [5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]\n# D = [100] * 10\nlabels_zero = [labels[0]]*D[0]\nlabels_one  = [labels[1]]*D[1]\nlabels_two  = [labels[2]]*D[2]\nlabels_three  = [labels[3]]*D[3]\nlabels_four  = [labels[4]]*D[4]\nlabels_five  = [labels[5]]*D[5]\nlabels_six  = [labels[6]]*D[6]\nlabels_seven  = [labels[7]]*D[7]\nlabels_eigth  = [labels[8]]*D[8]\nlabels_nineth  = [labels[9]]*D[9]\nlabels_zero = np.array(labels_zero,dtype = int)\nlabels_one = np.array(labels_one,dtype = int)\nlabels_two = np.array(labels_two,dtype = int)\nlabels_three = np.array(labels_three,dtype = int)\nlabels_four = np.array(labels_four,dtype = int)\nlabels_five = np.array(labels_five,dtype = int)\nlabels_six = np.array(labels_six,dtype = int)\nlabels_seven = np.array(labels_seven,dtype = int)\nlabels_eigth = np.array(labels_eigth,dtype = int)\nlabels_nineth = np.array(labels_nineth,dtype = int)\n\nlabels_new_train = np.concatenate((labels_zero,labels_one))\nlabels_new_train = np.concatenate((labels_new_train,labels_two))\nlabels_new_train = np.concatenate((labels_new_train,labels_three))\nlabels_new_train = np.concatenate((labels_new_train,labels_four))\nlabels_new_train = np.concatenate((labels_new_train,labels_five))\nlabels_new_train = np.concatenate((labels_new_train,labels_six))\nlabels_new_train = np.concatenate((labels_new_train,labels_seven))\nlabels_new_train = np.concatenate((labels_new_train,labels_eigth))\nlabels_new_train = np.concatenate((labels_new_train,labels_nineth))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:30:27.603006Z","iopub.execute_input":"2025-08-15T16:30:27.603236Z","iopub.status.idle":"2025-08-15T16:31:04.173813Z","shell.execute_reply.started":"2025-08-15T16:30:27.603212Z","shell.execute_reply":"2025-08-15T16:31:04.173170Z"}},"outputs":[{"name":"stderr","text":"2025-08-15 16:30:33.672528: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755275433.868395      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755275433.922480      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Loading the MNIST dataset\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nTrain: (60000, 784) (60000,)\nTest: (10000, 784) (10000,)\nnormalized_images shape:- (5923, 64)\nshape 1:- (5923, 64, 64)\nnormalized_images shape:- (6742, 64)\nshape 1:- (6742, 64, 64)\nnormalized_images shape:- (5958, 64)\nshape 1:- (5958, 64, 64)\nnormalized_images shape:- (6131, 64)\nshape 1:- (6131, 64, 64)\nnormalized_images shape:- (5842, 64)\nshape 1:- (5842, 64, 64)\nnormalized_images shape:- (5421, 64)\nshape 1:- (5421, 64, 64)\nnormalized_images shape:- (5918, 64)\nshape 1:- (5918, 64, 64)\nnormalized_images shape:- (6265, 64)\nshape 1:- (6265, 64, 64)\nnormalized_images shape:- (5851, 64)\nshape 1:- (5851, 64, 64)\nnormalized_images shape:- (5949, 64)\nshape 1:- (5949, 64, 64)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAxoAAABsCAYAAADt08QTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAO8UlEQVR4nO3deZTVZR3H8efeOzAzyAwgBsxYQjKi4EYlDEsuWSEV1rGY41LagtpmUjaguCZGpgQatpw5EpYVLdLiqUhDA0QDEgRLjoKOZiIDCM4CODPMzH36oyPnFJzP984zz9zF8379OZ879z58+N25fBv7fRPee+8AAAAAIKJkrg8AAAAA4K2HQQMAAABAdAwaAAAAAKJj0AAAAAAQHYMGAAAAgOgYNAAAAABEx6ABAAAAIDoGDQAAAADRMWgAAAAAiI5BAwAAAEB0eT9otLe3u2uvvdZVVla60tJSV11d7VasWJHrYxUEugtDb+HoLhzdhaO7cHQXht7C0V24guzO57mLLrrIFxUV+draWl9XV+cnTpzoi4qK/Jo1a3J9tLxHd2HoLRzdhaO7cHQXju7C0Fs4ugtXiN3l9aCxfv1675zz8+fPP/S11tZWP3LkSD9x4sQcniz/0V0YegtHd+HoLhzdhaO7MPQWju7CFWp3ef2fTi1btsylUil35ZVXHvpaSUmJmzFjhlu7dq175ZVXcni6/EZ3YegtHN2Fo7twdBeO7sLQWzi6C1eo3eX1oLFp0yY3atQoV15e/j9fHz9+vHPOuc2bN+fgVIWB7sLQWzi6C0d34eguHN2FobdwdBeuULvL60GjoaHBVVRUHPb1N7+2Y8eObB+pYNBdGHoLR3fh6C4c3YWjuzD0Fo7uwhVqd3k9aLS2trri4uLDvl5SUnIox5HRXRh6C0d34eguHN2Fo7sw9BaO7sIVand5PWiUlpa69vb2w77e1tZ2KMeR0V0YegtHd+HoLhzdhaO7MPQWju7CFWp3eT1oVFRUuIaGhsO+/ubXKisrs32kgkF3YegtHN2Fo7twdBeO7sLQWzi6C1eo3eX1oDF27Fi3bds219LS8j9fX79+/aEcR0Z3YegtHN2Fo7twdBeO7sLQWzi6C1ew3eX6/rrKunXrDrtncFtbm6+qqvLV1dU5PFn+o7sw9BaO7sLRXTi6C0d3YegtHN2FK9Tu8nrQ8N77mpoaX1RU5GfNmuXr6ur8pEmTfFFRkV+9enWuj5b36C4MvYWju3B0F47uwtFdGHoLR3fhCrG7vB80WltbfW1trR82bJgvLi7248aN8w899FCuj1UQ6C4MvYWju3B0F47uwtFdGHoLR3fhCrG7hPfe5+o/2wIAAADw1pTX/2dwAAAAAIWJQQMAAABAdAwaAAAAAKJj0AAAAAAQHYMGAAAAgOgYNAAAAABEx6ABAAAAILqiTB+YSGT80F6TSJT06Pu9b+vxGbzv7Pb35EN3ziVkmkqVybyrq6XHJ3irdmfr+aqa7naXD72Z71fjz+Rd96+Xw56Day78GQq2u9wr3O6s6673127la3fJZD+Z90mVy7y9Y2fM4xxRvnZnK7zrLj96y71MeuM3GgAAAACiY9AAAAAAEB2DBgAAAIDoGDQAAAAARMegAQAAACA6Bg0AAAAA0TFoAAAAAIgur24EPLD/KTLfXXu6zPfX63stD1m63DxDZ1eT+Zh8ZN3j+7Ih18h88eztMj/9tg7zDFsaf24+Jh+V9K2U+WMTamT+8gHd/SVP32ueoaNzj/mYfJMy7hv/1NmXyvz5Zr27ZfrG+RmcoiuDx2RbynzE5AFflPm94/Sf66iSgzI/9wn7eqpvfNB8TLZZ70XnnJs3cobMW7v0Pfkf2P2yzJ9u+pl5hvy87myD+p8m87tHni/z5a/qz9hf7bkjg1Pkojt9TUwdWGs+w59ub5J5+ooLZf6ZypUyX7rb7i7GbqHYEhn8M/Kmqutl/snjd8n8xo2DZf7A3tvNM2RjF0dspcVvl/k9J35G5gc69XX/tefuMs+QTu83H2PhNxoAAAAAomPQAAAAABAdgwYAAACA6Bg0AAAAAETHoAEAAAAgOgYNAAAAANExaAAAAACILuG9z+jmwolEz1ZuWDsynHPu9cUfkHnX9GkyT973gMwvvf4Y8wxLX5snc++7fx/rnnZn3fvcOeeenTpW5oN/eZnMkz9ZJvM53xxinuHOl+bKPBfdJRJ9zcf87j16x8i0lZP0Exw4IOMJJ/3VPMOGJr1ro7vdZaO3H5w8W+aXbz5Hv8auBpmPOcXe87CtUV+3vXPN6T0ZC0bre8Y759zMR0+SuR8yVOaJ9jaZ/3zSWvMMn346+z/rrHvuPzb5K+ZrTFj9EZmnVq7WT1Cu97ecNUXvFHLOucebF8k8Fz/rhpRXm49puEN/lli7IJJbnpH5hLOeNc/wZHOdzHuju8uG3ijzH/9M7xtwzrnxNTtlfsGQCpnP+eY+mT+60N6/M2W9vu7S6TfM5/h/Pb3upg6cZT7mj/88Vea+wtif8+2fyPioWx82z3CwY7c+Q5Y/Y63dLs45t2C0vm6v/ufZMk9u2yrzodU/Ms+wZ99TMs+kN36jAQAAACA6Bg0AAAAA0TFoAAAAAIiOQQMAAABAdAwaAAAAAKJj0AAAAAAQHYMGAAAAgOgYNAAAAABE19ONI4ckk/1k/sy548zneHyRnnumX3mDzK8aep7MbxqrF7Y459zSFfYSldj69tHL8OovsJcdbnlxsMy3nbVc5pua3ibz9i7zCHnp2AFnmo+Z9hd9bc579waZ33hLo8xTPtrbLCJ9nd9w/HXmM3z+Lr3r8+YTH5P53Hv1+/3iwWPMM9yqq+8VIwbpnzNfXXq0+Rx3vf85md+3U79fHz9fd98nOcI8Qy4cO1AvmJp8h71UdeWZD8m85plHZH7dsR+V+XdOsz8DJq7J/nvaWqL545N0t845lzhRf06nHn5U5m0PvyTz+Scbi9ecc+f8zV5M1336OZfcsEPmk6eXmq+woVkvVd3QpK+bWy4ZJPO9l+qfK845N2ZrjfmYbKsqKzEfk6z/l8wXTnle5tfcrxdNjljQap7BWu6abdUDvmA+5qqP18v8V2fof5hdPNP4t0my2DxDDPxGAwAAAEB0DBoAAAAAomPQAAAAABAdgwYAAACA6Bg0AAAAAETHoAEAAAAgOgYNAAAAANFFuxn4qAHTZD7kjA7zOYbfuljm6XSbzE+sOlfmf9+td038l74/fW+4YYS+n3LL66+az3H22jqZe5+W+TeqZsu8M539XmL4euUk8zGJ5atkXt8yQH//ML03YWvXb8wzZFtxn6Eyn/sd+77k98zU909fsneVzG/Z8E6Z/2LvAfMMuTCz4j0yb7pzo/kcs7f+VubpdLvMdzZcIfOOdPb3AWVifHK8zNPr9P30nXPuQxv0jpGDHXpf0reNH6dfmDzaPEPqb/3Nx8R24TGzZH5enb2DZM7H9X31l+zVO0jmHqd3PZw59HXzDAljh08Y/fl28MU3ZF7u7N03Nv0Z2dmpu1m8rsp8hePdwW6dKAZrR9pt79O7Hpxz7qcz9c/6RQ1Pyvyadr0jpo/Lzj6I7uhTpN+Pfzxvv/kc535PX5dr990t8/cuu1jmg5LvMM+wy601H2PhNxoAAAAAomPQAAAAABAdgwYAAACA6Bg0AAAAAETHoAEAAAAgOgYNAAAAANExaAAAAACILtoejbL0IJl37mk2n+PM/p+T+bxT9f23t+tbZbsZW35onqF36HOPHajvmV9+tL3T4Jyyz8v8vIoymV98wnaZj131lHmG3EjJtKZK/7mcc67rBX1v8vvm6r+fe67WOyma9m8xz5BtRalSmfvRx5vPceEYfX/tL3/xBJl//4eVMt/W+C3zDL1Dv19Hl+l9Ps9vt/f1JBL6R+/pA2tkPupS/f3Xzewyz5ALr3Y1yTx5whDzOT5WfrnMf9N4t8wnpKbIvK2lwTxD2sffZ5BI9JX5gsl6AciDV9h/50++rn+WTS3V3Uwf87LMJ6+wP6u86zQf0316h8Ul94+Q+Z8f1LsinHPulAv0ToKtLX+SeVnpcTK/fMIL5hmW/D77/9tw0rgu+9mrGNzGVfpzemq/apl3Pb5V5vUHVtqHyLIRZWfJvLPT/rvc1PYHmdcc/VWZp73eKfTi/lXmGWLgNxoAAAAAomPQAAAAABAdgwYAAACA6Bg0AAAAAETHoAEAAAAgOgYNAAAAANExaAAAAACILuG91zegfvOBxn3fjy4bK/M993/QfpGkvn/9175SIvN7ti+UeTq93z6Dwfvu3wPc6q5/6UiZP3LGNPM1xl2m7+3/o0Vvk/nVW5fIvO3gDvMMlt7oztp5cN/p15uv8amN75P5Sx/5tczHPKLzTmN3QCa6253VWzLZX+YvTL3IfI3hn9CvsWC+3olw/fOLZJ6L3pyzu5t53M0yX7jG3kHilj+hzzBY//3cPEfvxZn34p3mEbzXPzN6o7uEsbrpmuH2+/X2z9bLvKtZ75NI61US7rRf2Lsg6hsflHlYd8UyX/qua2Vec6G9M6jpKf1x/+9dA2U+ddM6mb/W8qR5BksuPifOHzTbfI3f3aJ3EiRH6n1Krl3vXll401HmGWqf1buFvDcu7iPo6Xv2uyfPMV/jqsXGn82nZbz0S/rfbp/afLt5BmvXSuzP2NLit8v8tc++13yNvsP0/pHtf9f7sCY+oXd47WrWu7AykUlv/EYDAAAAQHQMGgAAAACiY9AAAAAAEB2DBgAAAIDoGDQAAAAARMegAQAAACA6Bg0AAAAA0TFoAAAAAIgu2sI+SypVbr+GMffEWODVU72zTMj4fmNhjnPOpVJ6wVdnV7PxDBldBj2Si+6sxXTOOTdigF7Y96/mlTKPsQjSEnuZkP39ejlmJq+RTh8wnqEwrznrmjq1/BPma/RxfWW+3T8r853moiW9tC4TuXi/WovVnHOutPhYmQ/vN0nmuzqek3nj/n+YZ7Dk4robNeDD5mt0OL3Q7eWW1TLPxmdwbq67TF5D/0zsWzRQ5p3pN2Te1dXS3SMdJl//fTJ80BSZt6YbZf7avqdlnja6zUS2P2NL+laajzmm32iZ79y3Ueb58n7lNxoAAAAAomPQAAAAABAdgwYAAACA6Bg0AAAAAETHoAEAAAAgOgYNAAAAANExaAAAAACILuM9GgAAAACQKX6jAQAAACA6Bg0AAAAA0TFoAAAAAIiOQQMAAABAdAwaAAAAAKJj0AAAAAAQHYMGAAAAgOgYNAAAAABEx6ABAAAAILr/AJBqnzj9312GAAAAAElFTkSuQmCC\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"normalized_Hermitian_Digit_matrices shape:- torch.Size([60000, 64, 64])\nnormalized_hermitian_matrices_test_input shape:- torch.Size([10000, 64, 64])\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"Case 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import numpy as np\n# import torch\n# import torch.nn as nn\n# import torch.optim as optim\n# from torch.utils.data import DataLoader, TensorDataset\n# import time\n# from typing import Tuple\n\n# def set_seed(seed: int = 42) -> None:\n#     np.random.seed(seed)\n#     torch.manual_seed(seed)\n#     if torch.cuda.is_available():\n#         torch.cuda.manual_seed(seed)\n\n# class IntegratedHermitianClassifier(nn.Module):\n#     \"\"\"\n#     Learns:\n#         1. Hermitian base matrices  x, p\n#         2. Complex coefficients  a_k  per training sample\n#         3. A unitary matrix  U  that maps reconstructed Hamiltonians onto\n#           class-specific target Hamiltonians.\n\n#     Dual objectives (minimised together):\n#         1. Frobenius norm between reconstructed and original Hamiltonians.\n#         2. Frobenius norm between unitary-transformed reconstructions and\n#            class target Hamiltonians.\n\n#     Auxiliary term:\n#         1. Unitary constraint ‖U U† - I‖_F  +  ‖U† U - I‖_F.\n#     \"\"\"\n\n#     def __init__(\n#         self,\n#         matrix_size: int = 64,\n#         d_order: int = 3,\n#         lr: float = 1e-3,\n#         epochs: int = 50,\n#         batch_size: int = 128,\n#         device: str = None,\n#     ) -> None:\n#         super().__init__()\n\n#         # Hyper-parameters\n#         self.n = matrix_size\n#         self.d = d_order\n#         self.lr = lr\n#         self.epochs = epochs\n#         self.batch_size = batch_size\n#         self.device = torch.device(device or (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n\n#         # Trainable Hermitian bases (small init for stability)\n#         self.x = nn.Parameter(0.1 * torch.randn(matrix_size, matrix_size, dtype=torch.cfloat))\n#         self.p = nn.Parameter(0.1 * torch.randn(matrix_size, matrix_size, dtype=torch.cfloat))\n\n#         # Trainable unregularised matrix that will be exponentiated to unitary\n#         self.U_param = nn.Parameter(torch.randn(matrix_size, matrix_size, dtype=torch.cfloat))\n\n#         # Cached powers of  x  (x² … xᵈ)\n#         self.register_buffer(\"powers\", torch.zeros(d_order, matrix_size, matrix_size, dtype=torch.cfloat))\n#         self._powers_computed = False\n\n#         # Placeholders for data tensors\n#         self.Mtr: torch.Tensor = None\n#         self.Mte: torch.Tensor = None\n#         self.y:   torch.Tensor = None\n#         self.yte: torch.Tensor = None\n#         self.target_matrices: torch.Tensor = None\n\n#         self.to(self.device)\n\n#     @staticmethod\n#     def _make_hermitian(M: torch.Tensor) -> torch.Tensor:\n#         return 0.5 * (M + M.conj().transpose(-2, -1))\n\n#     @staticmethod\n#     def _frobenius_norm(mat: torch.Tensor) -> torch.Tensor:\n#         return torch.norm(mat, p=\"fro\", dim=(-2, -1), keepdim=True) + 1e-8\n\n#     def _normalise(self, M: torch.Tensor) -> torch.Tensor:\n#         return M / self._frobenius_norm(M)\n\n#     def make_unitary1(self,matrix):\n#       U,_,Vh = torch.linalg.svd(matrix,full_matrices = False)\n#       return U @ Vh\n\n#     def make_unitary2(self,matrix):\n#       Q,R = torch.linalg.qr(matrix)\n#       return Q\n\n#     def _make_unitary(self,matrix):\n#       H = self._make_hermitian(matrix)\n#       return torch.matrix_exp(-1j*H)\n\n#     @torch.no_grad()\n#     def _compute_powers(self) -> None:\n#         x_herm = self._make_hermitian(self._normalise(self.x))\n\n#         x_power = x_herm @ x_herm\n#         self.powers[0] = x_power\n#         for k in range(1, self.d):\n#             x_power = x_power @ x_herm\n#             self.powers[k] = x_power\n\n#         self._powers_computed = True\n\n#     def _base_hamiltonian(self) -> torch.Tensor:\n#         x_h = self._make_hermitian(self._normalise(self.x))\n#         p_h = self._make_hermitian(self._normalise(self.p))\n#         return self._make_hermitian(0.5 * (p_h @ p_h) + 0.5 * (x_h @ x_h))\n\n#     def _reconstruct_batch(self, coeffs: torch.Tensor) -> torch.Tensor:\n#         \"\"\"\n#         Reconstruct Hamiltonians for a batch of coefficient vectors.\n#         coeffs.shape == (batch, d)\n#         \"\"\"\n#         if not self._powers_computed:\n#             self._compute_powers()\n\n#         H0 = self._base_hamiltonian()\n#         batch = coeffs.shape[0]\n\n#         recon = H0.unsqueeze(0).expand(batch, -1, -1).clone()\n#         for k in range(self.d):\n#             recon = recon + coeffs[:, k].unsqueeze(-1).unsqueeze(-1) * self.powers[k]\n#         recon = 0.5 * (recon + recon.conj().transpose(-2, -1))\n#         return recon\n\n#     @staticmethod\n#     def _frobenius_batch(A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n#         diff = A - B\n#         # ||A-B||_F² = Tr((A-B)†(A-B))\n#         tr = torch.diagonal(diff.conj().transpose(-2, -1) @ diff, dim1=-2, dim2=-1).sum(-1)\n#         return torch.abs(tr)  # shape: (batch,)\n\n#     def load_data(\n#         self,\n#         train_mats: np.ndarray,\n#         train_labels: np.ndarray,\n#         test_mats: np.ndarray,\n#         test_labels: np.ndarray,\n#         target_mats: np.ndarray,\n#     ) -> None:\n#         print(f\"Loading data on {self.device} …\")\n\n#         self.Mtr  = torch.as_tensor(train_mats, dtype=torch.cfloat, device=self.device)\n#         self.y    = torch.as_tensor(train_labels, dtype=torch.long,  device=self.device)\n#         self.Mte  = torch.as_tensor(test_mats,  dtype=torch.cfloat, device=self.device)\n#         self.yte  = torch.as_tensor(test_labels, dtype=torch.long,  device=self.device)\n#         self.target_matrices = torch.as_tensor(target_mats, dtype=torch.cfloat, device=self.device)\n\n#         self._compute_powers()  # pre-compute x-powers once\n\n#         print(\n#             f\"Data loaded — train {self.Mtr.shape}, test {self.Mte.shape}\"\n#         )\n\n#     #Change here\n#     def forward(\n#         self,\n#         coeffs: torch.Tensor,             # (batch, d)\n#         originals: torch.Tensor,          # (batch, n, n)\n#         targets: torch.Tensor,            # (batch, n, n)\n#     ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n\n#         # 1 -  reconstruction loss\n#         reconstructed = self._reconstruct_batch(coeffs)\n#         L_recon = self._frobenius_batch(reconstructed, originals).mean()\n\n#         # 2 -  unitary mapping loss\n#         U = self.make_unitary1(self.U_param)\n#         transformed = U @ reconstructed @ U.conj().transpose(-2, -1)\n#         L_unitary = self._frobenius_batch(transformed, targets).mean()\n\n#         # 3 -  unitary constraint\n#         I = torch.eye(self.n, dtype=torch.cfloat, device=self.device)\n#         L_uc0 = torch.norm(U @ U.conj().T - I, p=\"fro\")\n#         L_uc1 = torch.norm(U.conj().T @ U - I, p=\"fro\")\n\n#         # weighted total\n#         total = L_recon + 10*L_unitary + 0.1 * (L_uc0 + L_uc1)\n#         return total, L_recon, L_unitary, L_uc0, L_uc1\n\n#     @torch.no_grad()\n#     def accuracy(self, mats: torch.Tensor, labels: torch.Tensor) -> float:\n#         U = self._make_unitary(self.U_param)\n#         outs = U @ mats @ U.conj().transpose(-2, -1)\n#         diag = torch.abs(torch.diagonal(outs, dim1=-2, dim2=-1))      # (batch, n)\n#         preds = torch.argmax(diag, dim=-1) // 7                        # 10 classes (positions spaced by 7)\n#         return torch.mean((preds == labels).float()).item()\n\n\n# class ComplexCoefficients(nn.Module):\n#     def __init__(self, d: int, n_samples: int, device: torch.device) -> None:\n#         super().__init__()\n#         std = 0.01 / np.sqrt(d)\n#         self.real = nn.Parameter(std * torch.randn(n_samples, d, device=device))\n#         self.imag = nn.Parameter(std * torch.randn(n_samples, d, device=device))\n\n#     def forward(self, idx: torch.Tensor) -> torch.Tensor:\n#         return torch.complex(self.real[idx], self.imag[idx])\n\n#     # handy accessor\n#     def all(self) -> torch.Tensor:\n#         return torch.complex(self.real, self.imag)\n\n# class ReduceLROnPlateau:\n#     def __init__(self, optimiser: optim.Optimizer, factor: float = 0.5, patience: int = 3, min_lr: float = 1e-8):\n#         self.opt = optimiser\n#         self.factor = factor\n#         self.patience = patience\n#         self.min_lr = min_lr\n#         self.best: float = None\n#         self.bad_epochs = 0\n\n#     def step(self, metric: float):\n#         if self.best is None or metric < self.best:\n#             self.best = metric\n#             self.bad_epochs = 0\n#             return\n#         self.bad_epochs += 1\n#         if self.bad_epochs >= self.patience:\n#             for pg in self.opt.param_groups:\n#                 new_lr = max(pg[\"lr\"] * self.factor, self.min_lr)\n#                 pg[\"lr\"] = new_lr\n#             self.bad_epochs = 0\n\n# def create_target_matrices(labels: np.ndarray, matrix_size: int = 64) -> np.ndarray:\n#     positions = [0, 7, 14, 21, 28, 35, 42, 49, 56, 63]\n#     out = np.zeros((len(labels), matrix_size, matrix_size), dtype=np.complex64)\n\n#     for i, lab in enumerate(labels):\n#         pos = positions[lab]\n#         out[i, pos, pos] = 1.0\n\n#     for i in range(len(out)):\n#         norm = np.linalg.norm(out[i], 'fro')\n#         if norm > 0:\n#             out[i] = out[i] / norm\n\n#     return out\n\n# def train_model(model: IntegratedHermitianClassifier) -> torch.Tensor:\n#     print(\"Training started …\")\n#     t0 = time.time()\n\n#     N = model.Mtr.shape[0]\n#     coeffs = ComplexCoefficients(model.d, N, model.device)\n\n#     opt_coeff   = optim.Adam(coeffs.parameters(), lr=model.lr)\n#     opt_bases   = optim.Adam([model.x, model.p], lr=model.lr * 0.1)\n#     opt_unitary = optim.Adam([model.U_param],     lr=model.lr * 0.05)\n\n#     sched_coeff   = ReduceLROnPlateau(opt_coeff)\n#     sched_bases   = ReduceLROnPlateau(opt_bases)\n#     sched_unitary = ReduceLROnPlateau(opt_unitary)\n\n#     ds = TensorDataset(model.Mtr, model.target_matrices, torch.arange(N, device=model.device))\n#     dl = DataLoader(ds, batch_size=model.batch_size, shuffle=True)\n\n#     for epoch in range(1, model.epochs + 1):\n#         print(f\"Epoch: {epoch}\")\n#         loss_sum = recon_sum = unit_sum = 0.0\n#         batches = 0\n\n#         for orig, tgt, idx in dl:\n#             a = coeffs(idx)\n\n#             opt_coeff.zero_grad()\n#             opt_bases.zero_grad()\n#             opt_unitary.zero_grad()\n\n#             tot, Lr, Lu, _, _ = model(a, orig, tgt)\n#             tot.backward()\n\n#             torch.nn.utils.clip_grad_norm_(coeffs.parameters(), 1.0)\n#             torch.nn.utils.clip_grad_norm_([model.x, model.p], 0.5)\n#             torch.nn.utils.clip_grad_norm_([model.U_param], 0.5)\n\n#             opt_coeff.step()\n#             opt_bases.step()\n#             opt_unitary.step()\n\n#             model._compute_powers()\n\n#             loss_sum  += tot.item()\n#             recon_sum += Lr.item()\n#             unit_sum  += Lu.item()\n#             batches   += 1\n\n#         sched_coeff.step(loss_sum / batches)\n#         sched_bases.step(recon_sum / batches)\n#         sched_unitary.step(unit_sum / batches)\n\n#         train_acc = model.accuracy(model.Mtr, model.y)\n#         test_acc  = model.accuracy(model.Mte, model.yte)\n\n#         print(\n#             f\"  Epoch {epoch:02d}/{model.epochs} | \"\n#             f\"Loss {loss_sum / batches:.4e} | \"\n#             f\"Recon {recon_sum / batches:.4e} | \"\n#             f\"Unit {unit_sum / batches:.4e} | \"\n#             f\"Acc train {train_acc:.3f} │ test {test_acc:.3f} | \"\n#             f\"Δt {time.time()-t0:.1f}s\"\n#         )\n\n#     print(f\"✓ Training finished in {time.time() - t0:.1f}s\")\n#     return coeffs.all()\n\n\n# def predict_coefficients(\n#     model: IntegratedHermitianClassifier,\n#     d_order: int,\n#     lr: float = 1e-3,\n#     epochs: int = 200,\n#     batch_size: int = 2000,\n# ) -> torch.Tensor:\n#     print(\"► Predicting coefficients for test set …\")\n#     Nt = model.Mte.shape[0]\n#     out = torch.empty((Nt, d_order), dtype=torch.cfloat, device=model.device)\n\n#     ds = TensorDataset(model.Mte, torch.arange(Nt, device=model.device))\n#     dl = DataLoader(ds, batch_size=batch_size)\n\n#     for mats, idx in dl:\n#         coeff = ComplexCoefficients(d_order, len(idx), model.device)\n#         opt = optim.Adam(coeff.parameters(), lr=lr)\n\n#         for _ in range(epochs):\n#             opt.zero_grad()\n#             preds = coeff(torch.arange(len(idx), device=model.device))\n#             recon = model._reconstruct_batch(preds)\n#             loss = model._frobenius_batch(recon, mats).mean()\n#             loss.backward()\n#             opt.step()\n\n#         out[idx] = coeff.all()\n#     print(\"✓ Coefficient prediction complete\")\n#     return out\n\n# def run_pipeline(\n#     train_mats: np.ndarray,\n#     train_labels: np.ndarray,\n#     test_mats: np.ndarray,\n#     test_labels: np.ndarray,\n#     *,\n#     matrix_size: int = 64,\n#     d_order: int = 10,\n#     lr: float = 5e-3,\n#     epochs: int = 50,\n#     batch_size: int = 128\n# ) -> Tuple[IntegratedHermitianClassifier, torch.Tensor, torch.Tensor]:\n\n#     set_seed(42)\n\n#     # Build class-specific target Hamiltonians\n#     targets = create_target_matrices(train_labels, matrix_size)\n\n#     # Initialise model and load data\n#     model = IntegratedHermitianClassifier(\n#         matrix_size=matrix_size,\n#         d_order=d_order,\n#         lr=lr,\n#         epochs=epochs,\n#         batch_size=batch_size,\n#     )\n#     model.load_data(train_mats, train_labels, test_mats, test_labels, targets)\n\n#     # Train\n#     train_coeffs = train_model(model)\n\n#     # Predict test coefficients\n#     test_coeffs = predict_coefficients(model, d_order, lr=lr * 0.1)\n\n#     # # Persist artefacts\n#     # save_results(train_coeffs, test_coeffs, model, out_dir)\n\n#     # Final accuracies\n#     print(\"\\n================ FINAL ACCURACY ================ \")\n#     print(f\"Train: {model.accuracy(model.Mtr, model.y):.3%}\")\n#     print(f\" Test: {model.accuracy(model.Mte, model.yte):.3%}\")\n#     print(\"===============================================\\n\")\n\n#     return model, train_coeffs, test_coeffs\n\n# def create_labels_from_class_counts(class_counts):\n#     labels = []\n#     for class_idx, count in enumerate(class_counts):\n#         labels.extend([class_idx] * count)\n#     return labels\n\n# class_counts = [5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]\n\n# train_X = normalized_Hermitian_Digit_matrices.numpy()\n# train_y = create_labels_from_class_counts(class_counts)\n# test_X = normalized_hermitian_matrices_test_input.numpy()\n# test_y = y_test\n\n# run_pipeline(train_X, train_y, test_X, test_y, matrix_size = 64, d_order = 10, lr = 1e-1, epochs = 10, batch_size = 20)\n\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Case 1 Updated code","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport time\nfrom typing import Tuple\n\ndef set_seed(seed: int = 42) -> None:\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n\nclass IntegratedHermitianClassifier(nn.Module):\n    def __init__(\n        self,\n        matrix_size: int = 64,\n        d_order: int = 3,\n        lr: float = 1e-3,\n        epochs: int = 50,\n        batch_size: int = 128,\n        device: str = None,\n    ) -> None:\n        super().__init__()\n\n        # Hyper-parameters\n        self.n = matrix_size\n        self.d = d_order\n        self.lr = lr\n        self.epochs = epochs\n        self.batch_size = batch_size\n        self.device = torch.device(device or (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n\n        # Trainable Hermitian bases (small init for stability)\n        self.x = nn.Parameter(0.1 * torch.randn(matrix_size, matrix_size, dtype=torch.cfloat))\n        self.p = nn.Parameter(0.1 * torch.randn(matrix_size, matrix_size, dtype=torch.cfloat))\n\n        # Trainable unregularised matrix that will be exponentiated to unitary\n        self.U_param = nn.Parameter(torch.randn(matrix_size, matrix_size, dtype=torch.cfloat))\n\n        # Cached powers of  x  (x² … xᵈ)\n        self.register_buffer(\"powers\", torch.zeros(d_order, matrix_size, matrix_size, dtype=torch.cfloat))\n        self._powers_computed = False\n\n        # Placeholders for data tensors\n        self.Mtr: torch.Tensor = None\n        self.Mte: torch.Tensor = None\n        self.y:   torch.Tensor = None\n        self.yte: torch.Tensor = None\n        self.target_matrices: torch.Tensor = None\n\n        self.to(self.device)\n\n    @staticmethod\n    def _make_hermitian(M: torch.Tensor) -> torch.Tensor:\n        return 0.5 * (M + M.conj().transpose(-2, -1))\n\n    @staticmethod\n    def _frobenius_norm(mat: torch.Tensor) -> torch.Tensor:\n        return torch.norm(mat, p=\"fro\", dim=(-2, -1), keepdim=True) + 1e-8\n\n    def _normalise(self, M: torch.Tensor) -> torch.Tensor:\n        return M / self._frobenius_norm(M)\n\n    # def _make_unitary(self, matrix):\n    #     U, _, Vh = torch.linalg.svd(matrix, full_matrices=False)\n    #     return U @ Vh\n\n    # Other Methods of Enforcing Unitary COnstraints that can be tried...\n    # def _make_unitary(self, matrix):\n    #     Q, R = torch.linalg.qr(matrix)\n    #     return Q\n\n    def _make_unitary(self, M: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Generates a unitary matrix through matrix exponential of a Hermitian:\n            U = exp(-i H),  H = (M + M†)/2\n        \"\"\"\n        H = self._make_hermitian(M)\n        return torch.matrix_exp(-1j * H)\n\n    @torch.no_grad()\n    def _compute_powers(self) -> None:\n        x_herm = self._make_hermitian(self._normalise(self.x))\n\n        x_power = x_herm @ x_herm\n        self.powers[0] = x_power\n        for k in range(1, self.d):\n            x_power = x_power @ x_herm\n            self.powers[k] = x_power\n\n        self._powers_computed = True\n\n    def _base_hamiltonian(self) -> torch.Tensor:\n        x_h = self._make_hermitian(self._normalise(self.x))\n        p_h = self._make_hermitian(self._normalise(self.p))\n        return self._make_hermitian(0.5 * (p_h @ p_h) + 0.5 * (x_h @ x_h))\n\n    def _reconstruct_batch(self, coeffs: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Reconstruct Hamiltonians for a batch of coefficient vectors.\n        coeffs.shape == (batch, d)\n        \"\"\"\n        if not self._powers_computed:\n            self._compute_powers()\n\n        H0 = self._base_hamiltonian()\n        batch = coeffs.shape[0]\n\n        recon = H0.unsqueeze(0).expand(batch, -1, -1).clone()\n        for k in range(self.d):\n            recon = recon + coeffs[:, k].unsqueeze(-1).unsqueeze(-1) * self.powers[k]\n        recon = 0.5 * (recon + recon.conj().transpose(-2, -1))\n        return recon\n\n    @staticmethod\n    def _frobenius_batch(A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n        diff = A - B\n        # ||A-B||_F² = Tr((A-B)†(A-B))\n        tr = torch.diagonal(diff.conj().transpose(-2, -1) @ diff, dim1=-2, dim2=-1).sum(-1)\n        return torch.abs(tr)  # shape: (batch,)\n\n    def load_data(\n        self,\n        train_mats: np.ndarray,\n        train_labels: np.ndarray,\n        test_mats: np.ndarray,\n        test_labels: np.ndarray,\n        target_mats: np.ndarray,\n    ) -> None:\n        print(f\"► Loading data on {self.device} …\")\n\n        self.Mtr  = torch.as_tensor(train_mats, dtype=torch.cfloat, device=self.device)\n        self.y    = torch.as_tensor(train_labels, dtype=torch.long,  device=self.device)\n        self.Mte  = torch.as_tensor(test_mats,  dtype=torch.cfloat, device=self.device)\n        self.yte  = torch.as_tensor(test_labels, dtype=torch.long,  device=self.device)\n        self.target_matrices = torch.as_tensor(target_mats, dtype=torch.cfloat, device=self.device)\n\n        self._compute_powers()  # pre-compute x-powers once\n\n        print(\n            f\"✓ Data loaded — train {self.Mtr.shape}, test {self.Mte.shape}\"\n        )\n\n    def forward(\n        self,\n        coeffs: torch.Tensor,             # (batch, d)\n        originals: torch.Tensor,          # (batch, n, n)\n        targets: torch.Tensor,            # (batch, n, n)\n    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n\n        # 1 -  reconstruction loss\n        reconstructed = self._reconstruct_batch(coeffs)\n        L_recon = self._frobenius_batch(reconstructed, originals).mean()\n\n        # 2 -  unitary mapping loss\n        U = self._make_unitary(self.U_param)\n        transformed = U @ reconstructed @ U.conj().transpose(-2, -1)\n        L_unitary = self._frobenius_batch(transformed, targets).mean()\n\n        # 3 -  unitary constraint\n        I = torch.eye(self.n, dtype=torch.cfloat, device=self.device)\n        L_uc0 = torch.norm(U @ U.conj().T - I, p=\"fro\")\n        L_uc1 = torch.norm(U.conj().T @ U - I, p=\"fro\")\n\n        # weighted total\n        total = L_recon + 10*L_unitary + 0.1 * (L_uc0 + L_uc1)\n        return total, L_recon, L_unitary, L_uc0, L_uc1\n\n    @torch.no_grad()\n    def accuracy(self, mats: torch.Tensor, labels: torch.Tensor) -> float:\n        U = self._make_unitary(self.U_param)\n        outs = U @ mats @ U.conj().transpose(-2, -1)\n        diag = torch.abs(torch.diagonal(outs, dim1=-2, dim2=-1))      # (batch, n)\n        preds = torch.argmax(diag, dim=-1) // 7                        # 10 classes (positions spaced by 7)\n        return torch.mean((preds == labels).float()).item()\n\nclass ComplexCoefficients(nn.Module):\n    def __init__(self, d: int, n_samples: int, device: torch.device) -> None:\n        super().__init__()\n        std = 0.01 / np.sqrt(d)\n        self.real = nn.Parameter(std * torch.randn(n_samples, d, device=device))\n        self.imag = nn.Parameter(std * torch.randn(n_samples, d, device=device))\n\n    def forward(self, idx: torch.Tensor) -> torch.Tensor:\n        return torch.complex(self.real[idx], self.imag[idx])\n\n    # handy accessor\n    def all(self) -> torch.Tensor:\n        return torch.complex(self.real, self.imag)\n\nclass ReduceLROnPlateau:\n    def __init__(self, optimiser: optim.Optimizer, factor: float = 0.5, patience: int = 3, min_lr: float = 1e-8):\n        self.opt = optimiser\n        self.factor = factor\n        self.patience = patience\n        self.min_lr = min_lr\n        self.best: float = None\n        self.bad_epochs = 0\n\n    def step(self, metric: float):\n        if self.best is None or metric < self.best:\n            self.best = metric\n            self.bad_epochs = 0\n            return\n        self.bad_epochs += 1\n        if self.bad_epochs >= self.patience:\n            for pg in self.opt.param_groups:\n                new_lr = max(pg[\"lr\"] * self.factor, self.min_lr)\n                pg[\"lr\"] = new_lr\n            self.bad_epochs = 0\n\n\ndef create_target_matrices(labels: np.ndarray, matrix_size: int = 64) -> np.ndarray:\n    positions = [0, 7, 14, 21, 28, 35, 42, 49, 56, 63]\n    out = np.zeros((len(labels), matrix_size, matrix_size), dtype=np.complex64)\n    \n    for i, lab in enumerate(labels):\n        pos = positions[lab]\n        out[i, pos, pos] = 1.0\n\n    for i in range(len(out)):\n        norm = np.linalg.norm(out[i], 'fro')\n        if norm > 0:\n            out[i] = out[i] / norm\n    \n    return out\n\n\ndef train_model(model: IntegratedHermitianClassifier) -> torch.Tensor:\n    print(\"► Training started …\")\n    t0 = time.time()\n\n    N = model.Mtr.shape[0]\n    coeffs = ComplexCoefficients(model.d, N, model.device)\n\n    opt_coeff   = optim.Adam(coeffs.parameters(), lr=model.lr)\n    opt_bases   = optim.Adam([model.x, model.p], lr=model.lr * 0.1)\n    opt_unitary = optim.Adam([model.U_param],     lr=model.lr * 0.05)\n\n    sched_coeff   = ReduceLROnPlateau(opt_coeff)\n    sched_bases   = ReduceLROnPlateau(opt_bases)\n    sched_unitary = ReduceLROnPlateau(opt_unitary)\n\n    ds = TensorDataset(model.Mtr, model.target_matrices, torch.arange(N, device=model.device))\n    dl = DataLoader(ds, batch_size=model.batch_size, shuffle=True)\n\n    for epoch in range(1, model.epochs + 1):\n        print(f\"Epoch: {epoch}\")\n        loss_sum = recon_sum = unit_sum = 0.0\n        batches = 0\n\n        for orig, tgt, idx in dl:\n            a = coeffs(idx)\n\n            opt_coeff.zero_grad()\n            opt_bases.zero_grad()\n            opt_unitary.zero_grad()\n\n            tot, Lr, Lu, _, _ = model(a, orig, tgt)\n            tot.backward()\n\n            torch.nn.utils.clip_grad_norm_(coeffs.parameters(), 1.0)\n            torch.nn.utils.clip_grad_norm_([model.x, model.p], 0.5)\n            torch.nn.utils.clip_grad_norm_([model.U_param], 0.5)\n\n            opt_coeff.step()\n            opt_bases.step()\n            opt_unitary.step()\n\n            model._compute_powers()  \n\n            loss_sum  += tot.item()\n            recon_sum += Lr.item()\n            unit_sum  += Lu.item()\n            batches   += 1\n\n        sched_coeff.step(loss_sum / batches)\n        sched_bases.step(recon_sum / batches)\n        sched_unitary.step(unit_sum / batches)\n\n        train_acc = model.accuracy(model.Mtr, model.y)\n        test_acc  = model.accuracy(model.Mte, model.yte)\n\n        print(\n            f\"  Epoch {epoch:02d}/{model.epochs} | \"\n            f\"Loss {loss_sum / batches:.4e} | \"\n            f\"Recon {recon_sum / batches:.4e} | \"\n            f\"Unit {unit_sum / batches:.4e} | \"\n            f\"Acc train {train_acc:.3f} │ test {test_acc:.3f} | \"\n            f\"Δt {time.time()-t0:.1f}s\"\n        )\n\n    print(f\"✓ Training finished in {time.time() - t0:.1f}s\")\n    return coeffs.all()\n\n\n# @torch.no_grad()\ndef predict_coefficients(\n    model: IntegratedHermitianClassifier,\n    d_order: int,\n    lr: float = 1e-3,\n    epochs: int = 200,\n    batch_size: int = 2000,\n) -> torch.Tensor:\n    print(\"► Predicting coefficients for test set …\")\n    Nt = model.Mte.shape[0]\n    out = torch.empty((Nt, d_order), dtype=torch.cfloat, device=model.device)\n\n    ds = TensorDataset(model.Mte, torch.arange(Nt, device=model.device))\n    dl = DataLoader(ds, batch_size=batch_size)\n\n    for mats, idx in dl:\n        coeff = ComplexCoefficients(d_order, len(idx), model.device)\n        opt = optim.Adam(coeff.parameters(), lr=lr)\n\n        for _ in range(epochs):\n            opt.zero_grad()\n            preds = coeff(torch.arange(len(idx), device=model.device))\n            recon = model._reconstruct_batch(preds)\n            loss = model._frobenius_batch(recon, mats).mean()\n            loss.backward()\n            opt.step()\n\n        out[idx] = coeff.all()\n    print(\"✓ Coefficient prediction complete\")\n    return out\n\ndef run_pipeline(\n    train_mats: np.ndarray,\n    train_labels: np.ndarray,\n    test_mats: np.ndarray,\n    test_labels: np.ndarray,\n    *,\n    matrix_size: int = 64,\n    d_order: int = 10,\n    lr: float = 5e-3,\n    epochs: int = 50,\n    batch_size: int = 128,\n    out_dir: str = \"./\",\n) -> Tuple[IntegratedHermitianClassifier, torch.Tensor, torch.Tensor]:\n\n    set_seed(42)\n\n    # Build class-specific target Hamiltonians\n    targets = create_target_matrices(train_labels, matrix_size)\n\n    # Initialise model and load data\n    model = IntegratedHermitianClassifier(\n        matrix_size=matrix_size,\n        d_order=d_order,\n        lr=lr,\n        epochs=epochs,\n        batch_size=batch_size,\n    )\n    model.load_data(train_mats, train_labels, test_mats, test_labels, targets)\n\n    # Train\n    train_coeffs = train_model(model)\n\n    # Predict test coefficients\n    #test_coeffs = predict_coefficients(model, d_order, lr=lr * 0.1)\n\n    # # Persist artefacts\n    # save_results(train_coeffs, test_coeffs, model, out_dir)\n\n    # Final accuracies\n    print(\"\\n================ FINAL ACCURACY ================ \")\n    print(f\"Train: {model.accuracy(model.Mtr, model.y):.3%}\")\n    print(f\" Test: {model.accuracy(model.Mte, model.yte):.3%}\")\n    print(\"===============================================\\n\")\n\n    return model, train_coeffs, test_coeffs\n\n\ndef create_labels_from_class_counts(class_counts):\n    labels = []\n    for class_idx, count in enumerate(class_counts):\n        labels.extend([class_idx] * count)\n    return labels\n\nclass_counts = [5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]\n\ntrain_X = normalized_Hermitian_Digit_matrices.numpy()\ntrain_y = create_labels_from_class_counts(class_counts)\ntest_X = normalized_hermitian_matrices_test_input.numpy()\ntest_y = y_test\n\nrun_pipeline(train_X, train_y, test_X, test_y, matrix_size = 64, d_order = 50, lr = 1e-1, epochs = 10, batch_size = 100)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Case 2","metadata":{}},{"cell_type":"code","source":"!pip uninstall optree","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from __future__ import annotations\nimport time\nfrom typing import Tuple, List\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\ndef set_seed(seed: int = 42) -> None:\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n\n\nclass IntegratedHermitianClassifier(nn.Module):\n    def __init__(\n        self,\n        matrix_size: int = 64,\n        n_classes: int = 10,\n        d_order: int = 10,\n        lr: float = 2e-3,\n        epochs: int = 100,\n        batch_size: int = 512,\n        device: str | None = None,\n    ) -> None:\n        super().__init__()\n\n        self.n, self.C, self.d = matrix_size, n_classes, d_order\n        self.lr, self.epochs, self.batch_size = lr, epochs, batch_size\n        self.device = torch.device(device or (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n\n        # class-wise Hermitian bases  (x_c , p_c)  → Parameters (C,n,n)\n        self.x_cls = nn.Parameter(0.1 * torch.randn(self.C, self.n, self.n, dtype=torch.cfloat))\n        self.p_cls = nn.Parameter(0.1 * torch.randn(self.C, self.n, self.n, dtype=torch.cfloat))\n\n        # global unconstrained parameter whose exponential is unitary\n        self.U_param = nn.Parameter(torch.randn(self.n, self.n, dtype=torch.cfloat))\n\n        # data placeholders\n        self.Mtr = self.Mte = self.y = self.yte = self.target_mats = None  \n\n        self.to(self.device)\n\n    @staticmethod\n    def _make_hermitian(M: torch.Tensor) -> torch.Tensor:\n        return 0.5 * (M + M.conj().transpose(-2, -1))\n\n    @staticmethod\n    def _fro(M: torch.Tensor) -> torch.Tensor:\n        return torch.norm(M, p=\"fro\", dim=(-2, -1), keepdim=True) + 1e-8\n\n    def _unitary(self) -> torch.Tensor:\n        H = self._make_hermitian(self.U_param)\n        return torch.matrix_exp(-1j * H)\n\n    def _reconstruct(\n        self,\n        coeffs: torch.Tensor,      # (B,d)\n        x_b:   torch.Tensor,       # (B,n,n)  — already class-selected\n        p_b:   torch.Tensor,       # (B,n,n)\n    ) -> torch.Tensor:\n        \"\"\"Vectorised reconstruction for a batch.\"\"\"\n        B = coeffs.shape[0]\n        x_h = self._make_hermitian(self._normalise(x_b := self._normalise(x_b)))\n        p_h = self._make_hermitian(self._normalise(p_b := self._normalise(p_b)))\n\n        H0 = self._make_hermitian(0.5 * (p_h @ p_h) + 0.5 * (x_h @ x_h))\n        powers = []\n        x_pow = x_h @ x_h\n        powers.append(x_pow)\n        for _ in range(1, self.d):\n            x_pow = x_pow @ x_h\n            powers.append(x_pow)\n\n        recon = H0.clone()\n        for k in range(self.d):\n            recon = recon + coeffs[:, k].view(B, 1, 1) * powers[k]\n        recon = 0.5 * (recon + recon.conj().transpose(-2, -1))\n        return recon\n\n    def _normalise(self, M: torch.Tensor) -> torch.Tensor:\n        return M / self._fro(M)\n\n    def forward(\n        self,\n        coeffs: torch.Tensor,      # (B,d)\n        labels: torch.Tensor,      # (B,)\n        originals: torch.Tensor,   # (B,n,n)\n        targets: torch.Tensor,     # (B,n,n)\n    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n\n        x_b = self.x_cls[labels]\n        p_b = self.p_cls[labels]\n        recon = self._reconstruct(coeffs, x_b, p_b)\n\n        diff     = recon - originals\n        L_recon  = torch.diagonal(diff.conj().transpose(-2, -1) @ diff,\n                                  dim1=-2, dim2=-1).sum(-1).abs().mean()\n\n        U  = self._unitary()\n        Uh = U.conj().transpose(-2, -1)\n        diffU = U @ recon @ Uh - targets\n        L_unit = torch.diagonal(diffU.conj().transpose(-2, -1) @ diffU,\n                                dim1=-2, dim2=-1).sum(-1).abs().mean()\n\n        I = torch.eye(self.n, dtype=torch.cfloat, device=self.device)\n        L_uc = torch.norm(U @ Uh - I, p=\"fro\") + torch.norm(Uh @ U - I, p=\"fro\")\n\n        total = L_recon + L_unit #+ 0.1 * L_uc\n        return total, L_recon, L_unit, L_uc\n\n    @torch.no_grad()\n    def accuracy_diag(self, mats: torch.Tensor, labels: torch.Tensor) -> float:\n        \"\"\"Quick diagnostic accuracy – diag( UHU† ).\"\"\"\n        U = self._unitary()\n        outs = U @ mats @ U.conj().transpose(-2, -1)\n        preds = torch.diagonal(outs.abs(), dim1=-2, dim2=-1).argmax(-1) // 7\n        return (preds == labels).float().mean().item()\n\n    def load_data(\n        self,\n        train_mats: np.ndarray,\n        train_labels: np.ndarray,\n        test_mats:  np.ndarray,\n        test_labels: np.ndarray,\n        target_mats: np.ndarray,\n    ) -> None:\n        print(f\"► Loading data on {self.device} …\")\n\n        self.Mtr = torch.tensor(train_mats, dtype=torch.cfloat, device=self.device)\n        self.y   = torch.tensor(train_labels, dtype=torch.long, device=self.device)\n        self.Mte = torch.tensor(test_mats,  dtype=torch.cfloat, device=self.device)\n        self.yte = torch.tensor(test_labels, dtype=torch.long, device=self.device)\n        self.target_mats = torch.tensor(target_mats, dtype=torch.cfloat, device=self.device)\n\n        print(f\"Data loaded — train {self.Mtr.shape}, test {self.Mte.shape}\")\n\n\nclass ComplexCoefficients(nn.Module):\n    def __init__(self, d: int, n_samples: int, device: torch.device):\n        super().__init__()\n        std = 0.01 / np.sqrt(d)\n        self.real = nn.Parameter(std * torch.randn(n_samples, d, device=device))\n        self.imag = nn.Parameter(std * torch.randn(n_samples, d, device=device))\n\n    def forward(self, idx: torch.Tensor) -> torch.Tensor:\n        return torch.complex(self.real[idx], self.imag[idx])\n\n    def all(self) -> torch.Tensor:\n        return torch.complex(self.real, self.imag)\n\nclass ReduceLROnPlateau:\n    def __init__(self, opt: optim.Optimizer, factor=.5, patience=3, min_lr=1e-8):\n        self.opt, self.factor, self.patience, self.min_lr = opt, factor, patience, min_lr\n        self.best, self.bad = None, 0\n\n    def step(self, metric: float):\n        if self.best is None or metric < self.best:\n            self.best, self.bad = metric, 0\n            return\n        self.bad += 1\n        if self.bad >= self.patience:\n            for pg in self.opt.param_groups:\n                pg[\"lr\"] = max(pg[\"lr\"] * self.factor, self.min_lr)\n            self.bad = 0\n\ndef create_target_matrices(labels: np.ndarray | List[int], n: int = 64) -> np.ndarray:\n    pos = [0, 7, 14, 21, 28, 35, 42, 49, 56, 63]\n    out = np.zeros((len(labels), n, n), np.complex64)\n    for i, lab in enumerate(labels):\n        out[i, pos[lab], pos[lab]] = 1.0\n    out /= np.linalg.norm(out, axis=(-2, -1), keepdims=True, ord='fro')\n    return out\n\n\ndef train(model: IntegratedHermitianClassifier) -> torch.Tensor:\n    print(\"► Training …\")\n    t0 = time.time()\n\n    N = model.Mtr.shape[0]\n    coeffs = ComplexCoefficients(model.d, N, model.device)\n\n    opt_coeff = optim.Adam(coeffs.parameters(), lr=model.lr)\n    opt_bases = optim.Adam([model.x_cls, model.p_cls], lr=model.lr * .1)\n    opt_unit  = optim.Adam([model.U_param],             lr=model.lr * .05)\n\n    sch_coeff = ReduceLROnPlateau(opt_coeff)\n    sch_bases = ReduceLROnPlateau(opt_bases)\n    sch_unit  = ReduceLROnPlateau(opt_unit)\n\n    ds = TensorDataset(model.Mtr, model.target_mats, model.y, torch.arange(N, device=model.device))\n    dl = DataLoader(ds, batch_size=model.batch_size, shuffle=True)\n\n    for ep in range(1, model.epochs + 1):\n        print(f\"Epoch: {ep}\")\n        tot_sum = rec_sum = unit_sum = 0.0; batches = 0\n        for H, T, lab, idx in dl:\n            a = coeffs(idx)\n\n            opt_coeff.zero_grad(); opt_bases.zero_grad(); opt_unit.zero_grad()\n            tot, Lr, Lu, L_uc = model(a, lab, H, T)\n            tot.backward()\n\n            torch.nn.utils.clip_grad_norm_(coeffs.parameters(), 1.0)\n            torch.nn.utils.clip_grad_norm_([model.x_cls, model.p_cls], .5)\n            torch.nn.utils.clip_grad_norm_([model.U_param], .5)\n\n            opt_coeff.step(); opt_bases.step(); opt_unit.step()\n\n            tot_sum += tot.item(); rec_sum += Lr.item(); unit_sum += Lu.item()\n            batches += 1\n\n        sch_coeff.step(tot_sum / batches)\n        sch_bases.step(rec_sum / batches)\n        sch_unit.step(unit_sum / batches)\n\n        print(f\"  Ep {ep:03d}/{model.epochs} | \"\n              f\"Loss {tot_sum/batches:.4e} | \"\n              f\"Recon {rec_sum/batches:.4e} | \"\n              f\"Unit {unit_sum/batches:.4e} | \"\n              f\"Acc {model.accuracy_diag(model.Mtr, model.y):.3f} │ \"\n              f\"Δt {time.time()-t0:.1f}s\")\n\n    print(\"Done  (training time {:.1f}s)\".format(time.time()-t0))\n    return coeffs.all()\n\n\ndef classify_test_set(\n    model: IntegratedHermitianClassifier,\n    d_order: int,\n    lr: float = 1e-3,\n    epochs: int = 100,\n    batch_size: int = 10000,\n    tol_target: float = 1e-3,\n) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Returns\n    -------\n    coeffs_out : (N_test,d)  coefficients of the chosen class per sample\n    preds      : (N_test,)   predicted class labels\n    \"\"\"\n    print(\"Classifying test set …\")\n    N = model.Mte.shape[0]\n    coeffs_out = torch.empty((N, d_order), dtype=torch.cfloat, device=model.device)\n    preds      = torch.empty(N, dtype=torch.long, device=model.device)\n\n    # pre-compute class targets (C,n,n)\n    tgt_cls = torch.tensor(create_target_matrices(list(range(model.C)), model.n),\n                           dtype=torch.cfloat, device=model.device)\n    U  = model._unitary()\n    Uh = U.conj().transpose(-2, -1)\n\n    ds = TensorDataset(model.Mte, torch.arange(N, device=model.device))\n    dl = DataLoader(ds, batch_size=batch_size, shuffle=False)\n\n    for H_batch, idx_batch in dl:\n        for j, idx in enumerate(idx_batch):\n            H = H_batch[j:j+1]     \n\n            best_match_loss = torch.inf\n            best_nomatch_loss = torch.inf\n            best_coeff = None\n            best_class = None\n            matched = False\n\n            for c in range(model.C):\n                coeff = ComplexCoefficients(d_order, 1, model.device)\n                opt   = optim.Adam(coeff.parameters(), lr=lr)\n\n                x_c = model.x_cls[c:c+1]  # (1,n,n)\n                p_c = model.p_cls[c:c+1]\n\n                for _ in range(epochs):\n                    opt.zero_grad()\n                    a = coeff(torch.tensor([0], device=model.device))\n                    recon = model._reconstruct(a, x_c, p_c)\n                    loss = (recon - H).abs().pow(2).sum()\n                    loss.backward()\n                    opt.step()\n\n                a_opt = coeff.all()  # (1,d)\n                recon = model._reconstruct(a_opt, x_c, p_c)\n                rec_loss = (recon - H).abs().pow(2).sum().item()\n\n                out = U @ recon @ Uh\n                tgt_diff = (out - tgt_cls[c:c+1]).abs().pow(2).sum().item()\n\n                if tgt_diff < tol_target:      # criterion 1 satisfied\n                    matched = True\n                    if rec_loss < best_match_loss:\n                        best_match_loss = rec_loss\n                        best_coeff, best_class = a_opt.squeeze(0), c\n                elif not matched and rec_loss < best_nomatch_loss:\n                    best_nomatch_loss = rec_loss\n                    best_coeff, best_class = a_opt.squeeze(0), c\n\n            coeffs_out[idx] = best_coeff\n            preds[idx]      = best_class\n\n    print(\"Classification complete\")\n    return coeffs_out, preds\n\n\ndef run_pipeline(\n    train_mats: np.ndarray,\n    train_labels: np.ndarray,\n    test_mats:  np.ndarray,\n    test_labels: np.ndarray,\n    *,\n    matrix_size: int = 64,\n    d_order: int = 10,\n    lr: float = 5e-3,\n    epochs: int = 200,\n    batch_size: int = 1024,\n) -> Tuple[IntegratedHermitianClassifier, torch.Tensor, torch.Tensor, torch.Tensor]:\n\n    set_seed(42)\n\n    tgt_train = create_target_matrices(train_labels, matrix_size)\n\n    model = IntegratedHermitianClassifier(\n        matrix_size=matrix_size,\n        d_order=d_order,\n        lr=lr,\n        epochs=epochs,\n        batch_size=batch_size,\n    )\n    model.load_data(train_mats, train_labels, test_mats, test_labels, tgt_train)\n\n    coeff_tr = train(model)\n    #coeff_te, preds_te = classify_test_set(model, d_order, lr=lr*0.1)\n\n    print(f\" Train diag-acc  : {model.accuracy_diag(model.Mtr, model.y):.3%}\")\n    print(f\" Test  diag-acc  : {model.accuracy_diag(model.Mte, model.yte):.3%}\")\n    #print(f\" Test  class-acc : {(preds_te.cpu().numpy()==test_labels).mean():.3%}\")\n\n    return model, coeff_tr, coeff_te, preds_te\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:31:48.896642Z","iopub.execute_input":"2025-08-15T16:31:48.897123Z","iopub.status.idle":"2025-08-15T16:31:48.934815Z","shell.execute_reply.started":"2025-08-15T16:31:48.897099Z","shell.execute_reply":"2025-08-15T16:31:48.934197Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"Case 2 GPU","metadata":{}},{"cell_type":"code","source":"def set_seed(seed: int = 42) -> None:\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\nclass IntegratedHermitianClassifier(nn.Module):\n    def __init__(\n        self,\n        matrix_size: int = 64,\n        n_classes: int = 10,\n        d_order: int = 10,\n        lr: float = 2e-3,\n        epochs: int = 100,\n        batch_size: int = 512,\n        device: str | None = None,\n    ) -> None:\n        super().__init__()\n\n        self.n, self.C, self.d = matrix_size, n_classes, d_order\n        self.lr, self.epochs, self.batch_size = lr, epochs, batch_size\n        self.device = torch.device(device or (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n\n        # class-wise Hermitian bases  (x_c , p_c) → Parameters (C,n,n)\n        self.x_cls = nn.Parameter(0.1 * torch.randn(self.C, self.n, self.n, dtype=torch.cfloat, device=self.device))\n        self.p_cls = nn.Parameter(0.1 * torch.randn(self.C, self.n, self.n, dtype=torch.cfloat, device=self.device))\n\n        # global unconstrained parameter whose exponential is unitary\n        self.U_param = nn.Parameter(torch.randn(self.n, self.n, dtype=torch.cfloat, device=self.device))\n\n        # data placeholders\n        self.Mtr = self.Mte = self.y = self.yte = self.target_mats = None  \n\n        self.to(self.device)\n\n    @staticmethod\n    def _make_hermitian(M: torch.Tensor) -> torch.Tensor:\n        return 0.5 * (M + M.conj().transpose(-2, -1))\n\n    @staticmethod\n    def _fro(M: torch.Tensor) -> torch.Tensor:\n        return torch.norm(M, p=\"fro\", dim=(-2, -1), keepdim=True) + 1e-8\n\n    def _unitary(self) -> torch.Tensor:\n        H = self._make_hermitian(self.U_param)\n        return torch.matrix_exp(-1j * H)\n\n    def _reconstruct(\n        self,\n        coeffs: torch.Tensor,      # (B,d)\n        x_b:   torch.Tensor,       # (B,n,n)  — already class-selected\n        p_b:   torch.Tensor,       # (B,n,n)\n    ) -> torch.Tensor:\n        \"\"\"Vectorised reconstruction for a batch.\"\"\"\n        B = coeffs.shape[0]\n        x_h = self._make_hermitian(self._normalise(x_b := self._normalise(x_b)))\n        p_h = self._make_hermitian(self._normalise(p_b := self._normalise(p_b)))\n\n        H0 = self._make_hermitian(0.5 * (p_h @ p_h) + 0.5 * (x_h @ x_h))\n        powers = []\n        x_pow = x_h @ x_h\n        powers.append(x_pow)\n        for _ in range(1, self.d):\n            x_pow = x_pow @ x_h\n            powers.append(x_pow)\n\n        recon = H0.clone()\n        for k in range(self.d):\n            recon = recon + coeffs[:, k].view(B, 1, 1) * powers[k]\n        recon = 0.5 * (recon + recon.conj().transpose(-2, -1))\n        return recon\n\n    def _normalise(self, M: torch.Tensor) -> torch.Tensor:\n        return M / self._fro(M)\n\n    def forward(\n        self,\n        coeffs: torch.Tensor,      # (B,d)\n        labels: torch.Tensor,      # (B,)\n        originals: torch.Tensor,   # (B,n,n)\n        targets: torch.Tensor,     # (B,n,n)\n    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n\n        x_b = self.x_cls[labels]\n        p_b = self.p_cls[labels]\n        recon = self._reconstruct(coeffs, x_b, p_b)\n\n        diff     = recon - originals\n        L_recon  = torch.diagonal(diff.conj().transpose(-2, -1) @ diff,\n                                  dim1=-2, dim2=-1).sum(-1).abs().mean()\n\n        U  = self._unitary()\n        Uh = U.conj().transpose(-2, -1)\n        diffU = U @ recon @ Uh - targets\n        L_unit = torch.diagonal(diffU.conj().transpose(-2, -1) @ diffU,\n                                dim1=-2, dim2=-1).sum(-1).abs().mean()\n\n        I = torch.eye(self.n, dtype=torch.cfloat, device=self.device)\n        L_uc = torch.norm(U @ Uh - I, p=\"fro\") + torch.norm(Uh @ U - I, p=\"fro\")\n\n        total = L_recon + L_unit #+ 0.1 * L_uc\n        return total, L_recon, L_unit, L_uc\n\n    @torch.no_grad()\n    def accuracy_diag(self, mats: torch.Tensor, labels: torch.Tensor) -> float:\n        \"\"\"Quick diagnostic accuracy – diag( UHU† ).\"\"\"\n        U = self._unitary()\n        outs = U @ mats @ U.conj().transpose(-2, -1)\n        preds = torch.diagonal(outs.abs(), dim1=-2, dim2=-1).argmax(-1) // 7\n        return (preds == labels).float().mean().item()\n\n    def load_data(\n        self,\n        train_mats: np.ndarray,\n        train_labels: np.ndarray,\n        test_mats:  np.ndarray,\n        test_labels: np.ndarray,\n        target_mats: np.ndarray,\n    ) -> None:\n        print(f\"► Loading data on {self.device} …\")\n\n        self.Mtr = torch.tensor(train_mats, dtype=torch.cfloat, device=self.device)\n        self.y   = torch.tensor(train_labels, dtype=torch.long, device=self.device)\n        self.Mte = torch.tensor(test_mats,  dtype=torch.cfloat, device=self.device)\n        self.yte = torch.tensor(test_labels, dtype=torch.long, device=self.device)\n        self.target_mats = torch.tensor(target_mats, dtype=torch.cfloat, device=self.device)\n\n        print(f\"Data loaded — train {self.Mtr.shape}, test {self.Mte.shape}\")\n\n\n    \n    # ... (rest of your class unchanged, since it already uses self.device) ...\n\n\ndef train(model: IntegratedHermitianClassifier) -> torch.Tensor:\n    print(\"► Training …\")\n    t0 = time.time()\n\n    N = model.Mtr.shape[0]\n    coeffs = ComplexCoefficients(model.d, N, model.device).to(model.device)\n\n    opt_coeff = optim.Adam(coeffs.parameters(), lr=model.lr)\n    opt_bases = optim.Adam([model.x_cls, model.p_cls], lr=model.lr * .1)\n    opt_unit  = optim.Adam([model.U_param],             lr=model.lr * .05)\n\n    sch_coeff = ReduceLROnPlateau(opt_coeff)\n    sch_bases = ReduceLROnPlateau(opt_bases)\n    sch_unit  = ReduceLROnPlateau(opt_unit)\n\n    ds = TensorDataset(model.Mtr, model.target_mats, model.y, torch.arange(N, device=model.device))\n    dl = DataLoader(ds, batch_size=model.batch_size, shuffle=True)\n\n    for ep in range(1, model.epochs + 1):\n        print(f\"Epoch: {ep}\")\n        tot_sum = rec_sum = unit_sum = 0.0; batches = 0\n        for H, T, lab, idx in dl:\n            # make sure batch is on GPU\n            H, T, lab, idx = H.to(model.device), T.to(model.device), lab.to(model.device), idx.to(model.device)\n\n            a = coeffs(idx)\n\n            opt_coeff.zero_grad(); opt_bases.zero_grad(); opt_unit.zero_grad()\n            tot, Lr, Lu, L_uc = model(a, lab, H, T)\n            tot.backward()\n\n            torch.nn.utils.clip_grad_norm_(coeffs.parameters(), 1.0)\n            torch.nn.utils.clip_grad_norm_([model.x_cls, model.p_cls], .5)\n            torch.nn.utils.clip_grad_norm_([model.U_param], .5)\n\n            opt_coeff.step(); opt_bases.step(); opt_unit.step()\n\n            tot_sum += tot.item(); rec_sum += Lr.item(); unit_sum += Lu.item()\n            batches += 1\n\n        sch_coeff.step(tot_sum / batches)\n        sch_bases.step(rec_sum / batches)\n        sch_unit.step(unit_sum / batches)\n\n        print(f\"  Ep {ep:03d}/{model.epochs} | \"\n              f\"Loss {tot_sum/batches:.4e} | \"\n              f\"Recon {rec_sum/batches:.4e} | \"\n              f\"Unit {unit_sum/batches:.4e} | \"\n              f\"Acc {model.accuracy_diag(model.Mtr, model.y):.3f} │ \"\n              f\"Δt {time.time()-t0:.1f}s\")\n\n    print(\"Done  (training time {:.1f}s)\".format(time.time()-t0))\n    return coeffs.all()\n\n\ndef classify_test_set(\n    model: IntegratedHermitianClassifier,\n    d_order: int,\n    lr: float = 1e-3,\n    epochs: int = 100,\n    batch_size: int = 10000,\n    tol_target: float = 1e-3,\n) -> Tuple[torch.Tensor, torch.Tensor]:\n\n    print(\"Classifying test set …\")\n    N = model.Mte.shape[0]\n    coeffs_out = torch.empty((N, d_order), dtype=torch.cfloat, device=model.device)\n    preds      = torch.empty(N, dtype=torch.long, device=model.device)\n\n    # pre-compute class targets (C,n,n)\n    tgt_cls = torch.tensor(create_target_matrices(list(range(model.C)), model.n),\n                           dtype=torch.cfloat, device=model.device)\n    U  = model._unitary()\n    Uh = U.conj().transpose(-2, -1)\n\n    ds = TensorDataset(model.Mte, torch.arange(N, device=model.device))\n    dl = DataLoader(ds, batch_size=batch_size, shuffle=False)\n\n    for H_batch, idx_batch in dl:\n        H_batch, idx_batch = H_batch.to(model.device), idx_batch.to(model.device)\n\n        for j, idx in enumerate(idx_batch):\n            H = H_batch[j:j+1].to(model.device)\n\n            best_match_loss = torch.inf\n            best_nomatch_loss = torch.inf\n            best_coeff = None\n            best_class = None\n            matched = False\n\n            for c in range(model.C):\n                coeff = ComplexCoefficients(d_order, 1, model.device).to(model.device)\n                opt   = optim.Adam(coeff.parameters(), lr=lr)\n\n                x_c = model.x_cls[c:c+1].to(model.device)  # (1,n,n)\n                p_c = model.p_cls[c:c+1].to(model.device)\n\n                for _ in range(epochs):\n                    opt.zero_grad()\n                    a = coeff(torch.tensor([0], device=model.device))\n                    recon = model._reconstruct(a, x_c, p_c)\n                    loss = (recon - H).abs().pow(2).sum()\n                    loss.backward()\n                    opt.step()\n\n                a_opt = coeff.all()  # (1,d)\n                recon = model._reconstruct(a_opt, x_c, p_c)\n                rec_loss = (recon - H).abs().pow(2).sum().item()\n\n                out = U @ recon @ Uh\n                tgt_diff = (out - tgt_cls[c:c+1]).abs().pow(2).sum().item()\n\n                if tgt_diff < tol_target:\n                    matched = True\n                    if rec_loss < best_match_loss:\n                        best_match_loss = rec_loss\n                        best_coeff, best_class = a_opt.squeeze(0), c\n                elif not matched and rec_loss < best_nomatch_loss:\n                    best_nomatch_loss = rec_loss\n                    best_coeff, best_class = a_opt.squeeze(0), c\n\n            coeffs_out[idx] = best_coeff\n            preds[idx]      = best_class\n\n    print(\"Classification complete\")\n    return coeffs_out, preds\n\n\ndef create_labels_from_class_counts(class_counts):\n    labels = []\n    for class_idx, count in enumerate(class_counts):\n        labels.extend([class_idx] * count)\n    return labels\n\nclass_counts = [5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]\n\ntrain_X = normalized_Hermitian_Digit_matrices.numpy()\ntrain_y = create_labels_from_class_counts(class_counts)\ntest_X = normalized_hermitian_matrices_test_input.numpy()\ntest_y = y_test\n\nrun_pipeline(train_X, train_y, test_X, test_y, matrix_size = 64, d_order = 90, lr = 1e-1, epochs = 10, batch_size = 100)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:31:51.635645Z","iopub.execute_input":"2025-08-15T16:31:51.636101Z","iopub.status.idle":"2025-08-15T16:37:44.362943Z","shell.execute_reply.started":"2025-08-15T16:31:51.636077Z","shell.execute_reply":"2025-08-15T16:37:44.362062Z"}},"outputs":[{"name":"stdout","text":"► Loading data on cuda …\nData loaded — train torch.Size([60000, 64, 64]), test torch.Size([10000, 64, 64])\n► Training …\nEpoch: 1\n  Ep 001/10 | Loss 9.4986e-01 | Recon 6.7640e-01 | Unit 2.7346e-01 | Acc 0.650 │ Δt 37.3s\nEpoch: 2\n  Ep 002/10 | Loss 6.2142e+00 | Recon 3.2500e+00 | Unit 2.9643e+00 | Acc 0.716 │ Δt 70.8s\nEpoch: 3\n  Ep 003/10 | Loss 9.8836e-01 | Recon 6.5283e-01 | Unit 3.3553e-01 | Acc 0.711 │ Δt 104.8s\nEpoch: 4\n  Ep 004/10 | Loss 9.2122e-01 | Recon 6.3455e-01 | Unit 2.8667e-01 | Acc 0.669 │ Δt 139.6s\nEpoch: 5\n  Ep 005/10 | Loss 8.9683e-01 | Recon 6.3019e-01 | Unit 2.6664e-01 | Acc 0.660 │ Δt 174.1s\nEpoch: 6\n  Ep 006/10 | Loss 8.9357e-01 | Recon 6.2969e-01 | Unit 2.6388e-01 | Acc 0.670 │ Δt 208.7s\nEpoch: 7\n  Ep 007/10 | Loss 8.8905e-01 | Recon 6.2609e-01 | Unit 2.6296e-01 | Acc 0.668 │ Δt 243.2s\nEpoch: 8\n  Ep 008/10 | Loss 8.8595e-01 | Recon 6.2325e-01 | Unit 2.6270e-01 | Acc 0.677 │ Δt 277.7s\nEpoch: 9\n  Ep 009/10 | Loss 8.8434e-01 | Recon 6.2013e-01 | Unit 2.6421e-01 | Acc 0.677 │ Δt 312.2s\nEpoch: 10\n  Ep 010/10 | Loss 8.8224e-01 | Recon 6.1764e-01 | Unit 2.6460e-01 | Acc 0.675 │ Δt 346.6s\nDone  (training time 346.6s)\n Train diag-acc  : 67.455%\n Test  diag-acc  : 68.480%\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3508097367.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m \u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3213104724.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(train_mats, train_labels, test_mats, test_labels, matrix_size, d_order, lr, epochs, batch_size)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;31m#print(f\" Test  class-acc : {(preds_te.cpu().numpy()==test_labels).mean():.3%}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeff_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeff_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_te\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'coeff_te' is not defined"],"ename":"NameError","evalue":"name 'coeff_te' is not defined","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"import torch\n\ntorch.cuda.empty_cache()   # releases all unused cached memory back to the GPU\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:12:01.229036Z","iopub.execute_input":"2025-08-15T16:12:01.229273Z","iopub.status.idle":"2025-08-15T16:12:01.247243Z","shell.execute_reply.started":"2025-08-15T16:12:01.229257Z","shell.execute_reply":"2025-08-15T16:12:01.246244Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2489425355.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# releases all unused cached memory back to the GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mtensor_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tensor_name' is not defined"],"ename":"NameError","evalue":"name 'tensor_name' is not defined","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"print(torch.cuda.memory_summary())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:12:16.774160Z","iopub.execute_input":"2025-08-15T16:12:16.774461Z","iopub.status.idle":"2025-08-15T16:12:16.779214Z","shell.execute_reply.started":"2025-08-15T16:12:16.774440Z","shell.execute_reply":"2025-08-15T16:12:16.778443Z"}},"outputs":[{"name":"stdout","text":"|===========================================================================|\n|                  PyTorch CUDA memory summary, device ID 0                 |\n|---------------------------------------------------------------------------|\n|            CUDA OOMs: 2            |        cudaMalloc retries: 2         |\n|===========================================================================|\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n|---------------------------------------------------------------------------|\n| Allocated memory      |  11901 MiB |  11901 MiB |   1966 GiB |   1954 GiB |\n|       from large pool |  11889 MiB |  11889 MiB |   1954 GiB |   1942 GiB |\n|       from small pool |     11 MiB |     11 MiB |     11 GiB |     11 GiB |\n|---------------------------------------------------------------------------|\n| Active memory         |  11901 MiB |  11901 MiB |   1966 GiB |   1954 GiB |\n|       from large pool |  11889 MiB |  11889 MiB |   1954 GiB |   1942 GiB |\n|       from small pool |     11 MiB |     11 MiB |     11 GiB |     11 GiB |\n|---------------------------------------------------------------------------|\n| Requested memory      |  11862 MiB |  11862 MiB |   1922 GiB |   1910 GiB |\n|       from large pool |  11851 MiB |  11851 MiB |   1910 GiB |   1898 GiB |\n|       from small pool |     11 MiB |     11 MiB |     11 GiB |     11 GiB |\n|---------------------------------------------------------------------------|\n| GPU reserved memory   |  13178 MiB |  14542 MiB |  14542 MiB |   1364 MiB |\n|       from large pool |  13166 MiB |  14530 MiB |  14530 MiB |   1364 MiB |\n|       from small pool |     12 MiB |     12 MiB |     12 MiB |      0 MiB |\n|---------------------------------------------------------------------------|\n| Non-releasable memory |   1276 MiB |   1611 MiB | 262986 MiB | 261709 MiB |\n|       from large pool |   1276 MiB |   1608 MiB | 250446 MiB | 249170 MiB |\n|       from small pool |      0 MiB |      3 MiB |  12539 MiB |  12539 MiB |\n|---------------------------------------------------------------------------|\n| Allocations           |     189    |     221    |  393680    |  393491    |\n|       from large pool |     108    |     181    |  176699    |  176591    |\n|       from small pool |      81    |     105    |  216981    |  216900    |\n|---------------------------------------------------------------------------|\n| Active allocs         |     189    |     221    |  393680    |  393491    |\n|       from large pool |     108    |     181    |  176699    |  176591    |\n|       from small pool |      81    |     105    |  216981    |  216900    |\n|---------------------------------------------------------------------------|\n| GPU reserved segments |     111    |     195    |     195    |      84    |\n|       from large pool |     105    |     189    |     189    |      84    |\n|       from small pool |       6    |       6    |       6    |       0    |\n|---------------------------------------------------------------------------|\n| Non-releasable allocs |      27    |      31    |  145811    |  145784    |\n|       from large pool |      11    |      14    |   41710    |   41699    |\n|       from small pool |      16    |      19    |  104101    |  104085    |\n|---------------------------------------------------------------------------|\n| Oversize allocations  |       0    |       0    |       0    |       0    |\n|---------------------------------------------------------------------------|\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\n|===========================================================================|\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}