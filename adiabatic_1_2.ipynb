{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-12T06:45:47.506667Z","iopub.execute_input":"2025-08-12T06:45:47.507053Z","iopub.status.idle":"2025-08-12T06:45:47.513490Z","shell.execute_reply.started":"2025-08-12T06:45:47.507012Z","shell.execute_reply":"2025-08-12T06:45:47.512532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data Preprocessing of the MNIST Dataset to produce the train and test normalized Hamiitonians...\n# We can construct the hamiltonians from the four methods described in the paper...\nimport numpy as np\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport torch\nfrom sklearn.datasets import fetch_openml\nimport scipy\n\n# ----------------------------\n# Load MNIST from OpenML\n# ----------------------------\n# mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n\n# mnist_images = mnist.data.astype(np.float64)   # (70000, 784)\n# mnist_labels = mnist.target.astype(int)        # (70000,)\n\n# x_train = mnist_images[:60000]\n# y_train = mnist_labels[:60000]\n# x_test  = mnist_images[60000:60201]\n# y_test  = mnist_labels[60000:60201]\n\n#OR\n\nfrom tensorflow.keras.datasets import mnist\n\n# Load MNIST using Keras\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# # Reshape and convert to float64 for consistency\nx_train = x_train.reshape(-1, 784).astype(np.float64)\nx_test = x_test.reshape(-1, 784).astype(np.float64)\nprint(\"Train:\", x_train.shape, y_train.shape)\nprint(\"Test:\", x_test.shape, y_test.shape)\n\n# ----------------------------\n# Helper functions\n# ----------------------------\ndef separate_digits(images, labels):\n    \"\"\"Group images by digit label.\"\"\"\n    digit_image = {d: [] for d in range(10)}\n    for img, lbl in zip(images, labels):\n        digit_image[lbl].append(img)\n    return digit_image\n\ndef resize_images_batch(images, new_size=(8, 8), batch_size=500):\n    \"\"\"Resize a batch of flattened 28x28 images to new_size.\"\"\"\n    n = len(images)\n    resized = []\n    for i in range(0, n, batch_size):\n        batch = images[i:i+batch_size]\n        resized_batch = [resize(img.reshape(28,28), new_size).flatten() for img in batch]\n        resized.extend(resized_batch)\n    return np.array(resized)\n\ndef normalize_batch(images):\n    \"\"\"Normalize each image vector.\"\"\"\n    norms = np.linalg.norm(images, axis=1, keepdims=True)\n    return images / norms\n\n#Creating Hamiltonian using outer product method\ndef density_matrix_batch(images):\n    \"\"\"Convert vectors to density matrices.\"\"\"\n    return np.matmul(images[:,:,np.newaxis], images[:,np.newaxis,:])\n\n#Creating the Hamiltonian using H = A + A.T/2 method\ndef hamiltonian_symmetric_batch(images):\n  N,D = images.shape\n  H_list = []\n  for i in range(N):\n    a = images[i]\n    A = np.outer(a,np.ones(D))\n    H = (A + A.conj().T) / 2\n    H_list.append(H)\n\n  return np.array(H_list)\n\n#Creating the Hamiltonian using H = A @ A.T method\ndef hamiltonian_product_batch(images):\n  N , D = images.shape\n  H_list = []\n  for i in range(N):\n    a = images[i]\n    A = np.outer(a,np.ones(D))\n    H = A @ A.T\n    H_list.append(H)\n  return np.array(H_list)\n\nimport scipy.linalg\n#Creating thr Hamiltonian using H = -i * log(V) method\ndef hamiltonian_using_log(images):\n    def make_unitary1(matrix):\n        U, _, Vh = torch.linalg.svd(matrix, full_matrices=False)\n        return U @ Vh\n    \n    def make_unitary2(matrix):\n        matrix = matrix / (torch.linalg.norm(matrix) + 1e-12) #for -i log(V) case only\n        Q,R = torch.linalg.qr(matrix)\n        return Q\n            \n    N , D = images.shape\n    hamiltonians = np.zeros((N,D,D), dtype = np.complex128)\n    for i in range(N):\n        image = images[i]\n        mat = np.diag(image)\n        mat_torch = torch.tensor(mat,dtype = torch.complex128)\n        U_torch = make_unitary2(mat_torch)\n        U_np = U_torch.detach().cpu().numpy()\n        H = -1j * scipy.linalg.logm(U_np)\n        H = (H + H.conj().T) / 2\n        hamiltonians[i] = H\n\n    return hamiltonians\n        \n\n# ----------------------------\n# Process training data\n# ----------------------------\ndigit_images_dict = separate_digits(x_train, y_train)\nresized_digit_images = {}\nnormalized_digit_images = {}\ndensity_matrices = {}\n\nfor digit, imgs in digit_images_dict.items():\n    imgs = np.array(imgs)\n    imgs_resized = resize_images_batch(imgs, new_size=(8,8), batch_size=500)\n    imgs_normalized = normalize_batch(imgs_resized)\n    print(f\"normalized_images shape:- {imgs_normalized.shape}\")\n    density1 = density_matrix_batch(imgs_normalized)\n    print(f\"shape 1:- {density1.shape}\")\n    #OR\n    density2 = hamiltonian_symmetric_batch(imgs_normalized)\n    print(f\"shape 2:- {density2.shape}\")\n    #OR\n    density3 = hamiltonian_product_batch(imgs_normalized)\n    print(f\"shape 3:- {density3.shape}\")\n    #OR\n    density4 = hamiltonian_using_log(imgs_normalized)\n    print(f\"shape 4:- {density4.shape}\")\n    density1 /= np.linalg.norm(density1, axis=(1,2), keepdims=True)\n    density2 /= np.linalg.norm(density2, axis=(1,2), keepdims=True)\n    density3 /= np.linalg.norm(density3, axis=(1,2), keepdims=True)\n    density4 /= np.linalg.norm(density4, axis=(1,2), keepdims=True)\n    resized_digit_images[digit] = imgs_resized\n    normalized_digit_images[digit] = imgs_normalized\n    density_matrices[digit] = density1\n    #density_matrices[digit] = density2\n    #density_matrices[digit] = density3\n    #density_matrices[digit] = density4\n\ntrain_density_matrices = np.concatenate([density_matrices[d] for d in range(10)], axis=0)\ntrain_density_matrices_tensor = torch.tensor(train_density_matrices, dtype=torch.cfloat)\n\n# ----------------------------\n# Process test data\n# ----------------------------\ntest_images_resized = np.array([resize(img.reshape(28,28), (8,8)).flatten() for img in x_test])\ntest_normed = normalize_batch(test_images_resized)\ntest_density = density_matrix_batch(test_normed)\ntest_density /= np.linalg.norm(test_density, axis=(1,2), keepdims=True)\ntest_density_tensor = torch.tensor(test_density, dtype=torch.cfloat)\n\n# ----------------------------\n# Visualization example\n# ---------------------------\n\nfor digit in range(10):\n    images_to_plot = resized_digit_images[digit][:10]\n    plt.figure(figsize=(10,2))\n    for i in range(10):\n        plt.subplot(1, 10, i+1)\n        plt.imshow(images_to_plot[i].reshape(8,8), cmap='magma')\n        plt.title(f\"{digit}\")\n        plt.axis('off')\n    plt.show()\n\nnormalized_Hermitian_Digit_matrices = train_density_matrices_tensor\n# normalized_Hermitian_Digit_matrices = torch.tensor(train_subset,dtype = torch.cfloat)\nnormalized_hermitian_matrices_test_input = test_density_tensor\n# normalized_hermitian_matrices_test_input = torch.tensor(test_subset,dtype = torch.cfloat)\n\nprint(f\"normalized_Hermitian_Digit_matrices shape:- {normalized_Hermitian_Digit_matrices.shape}\")\nprint(f\"normalized_hermitian_matrices_test_input shape:- {normalized_hermitian_matrices_test_input.shape}\")\n# normalized_Hermitian_Digit_matrices_small = torch.tensor(train_subset_small,dtype = torch.cfloat)\n# normalized_hermitian_matrices_test_input_small = torch.tensor(test_subset_small,dtype = torch.cfloat)\n\n\nlabels = []\nfor i in range(10):\n    labels.append(i)\n\nprint(labels)\n\nD = [5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]\n# D = [100] * 10\nlabels_zero = [labels[0]]*D[0]\nlabels_one  = [labels[1]]*D[1]\nlabels_two  = [labels[2]]*D[2]\nlabels_three  = [labels[3]]*D[3]\nlabels_four  = [labels[4]]*D[4]\nlabels_five  = [labels[5]]*D[5]\nlabels_six  = [labels[6]]*D[6]\nlabels_seven  = [labels[7]]*D[7]\nlabels_eigth  = [labels[8]]*D[8]\nlabels_nineth  = [labels[9]]*D[9]\nlabels_zero = np.array(labels_zero,dtype = int)\nlabels_one = np.array(labels_one,dtype = int)\nlabels_two = np.array(labels_two,dtype = int)\nlabels_three = np.array(labels_three,dtype = int)\nlabels_four = np.array(labels_four,dtype = int)\nlabels_five = np.array(labels_five,dtype = int)\nlabels_six = np.array(labels_six,dtype = int)\nlabels_seven = np.array(labels_seven,dtype = int)\nlabels_eigth = np.array(labels_eigth,dtype = int)\nlabels_nineth = np.array(labels_nineth,dtype = int)\n\nlabels_new_train = np.concatenate((labels_zero,labels_one))\nlabels_new_train = np.concatenate((labels_new_train,labels_two))\nlabels_new_train = np.concatenate((labels_new_train,labels_three))\nlabels_new_train = np.concatenate((labels_new_train,labels_four))\nlabels_new_train = np.concatenate((labels_new_train,labels_five))\nlabels_new_train = np.concatenate((labels_new_train,labels_six))\nlabels_new_train = np.concatenate((labels_new_train,labels_seven))\nlabels_new_train = np.concatenate((labels_new_train,labels_eigth))\nlabels_new_train = np.concatenate((labels_new_train,labels_nineth))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T07:15:57.417987Z","iopub.execute_input":"2025-08-13T07:15:57.418523Z","iopub.status.idle":"2025-08-13T07:24:53.420235Z","shell.execute_reply.started":"2025-08-13T07:15:57.418482Z","shell.execute_reply":"2025-08-13T07:24:53.419254Z"}},"outputs":[{"name":"stderr","text":"2025-08-13 07:16:02.685862: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755069362.979653      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755069363.063949      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nTrain: (60000, 784) (60000,)\nTest: (10000, 784) (10000,)\nnormalized_images shape:- (5923, 64)\nshape 1:- (5923, 64, 64)\nshape 2:- (5923, 64, 64)\nshape 3:- (5923, 64, 64)\nshape 4:- (5923, 64, 64)\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/1616982615.py:144: RuntimeWarning: invalid value encountered in divide\n  density4 /= np.linalg.norm(density4, axis=(1,2), keepdims=True)\n","output_type":"stream"},{"name":"stdout","text":"normalized_images shape:- (6742, 64)\nshape 1:- (6742, 64, 64)\nshape 2:- (6742, 64, 64)\nshape 3:- (6742, 64, 64)\nshape 4:- (6742, 64, 64)\nnormalized_images shape:- (5958, 64)\nshape 1:- (5958, 64, 64)\nshape 2:- (5958, 64, 64)\nshape 3:- (5958, 64, 64)\nshape 4:- (5958, 64, 64)\nnormalized_images shape:- (6131, 64)\nshape 1:- (6131, 64, 64)\nshape 2:- (6131, 64, 64)\nshape 3:- (6131, 64, 64)\nshape 4:- (6131, 64, 64)\nnormalized_images shape:- (5842, 64)\nshape 1:- (5842, 64, 64)\nshape 2:- (5842, 64, 64)\nshape 3:- (5842, 64, 64)\nshape 4:- (5842, 64, 64)\nnormalized_images shape:- (5421, 64)\nshape 1:- (5421, 64, 64)\nshape 2:- (5421, 64, 64)\nshape 3:- (5421, 64, 64)\nshape 4:- (5421, 64, 64)\nnormalized_images shape:- (5918, 64)\nshape 1:- (5918, 64, 64)\nshape 2:- (5918, 64, 64)\nshape 3:- (5918, 64, 64)\nshape 4:- (5918, 64, 64)\nnormalized_images shape:- (6265, 64)\nshape 1:- (6265, 64, 64)\nshape 2:- (6265, 64, 64)\nshape 3:- (6265, 64, 64)\nshape 4:- (6265, 64, 64)\nnormalized_images shape:- (5851, 64)\nshape 1:- (5851, 64, 64)\nshape 2:- (5851, 64, 64)\nshape 3:- (5851, 64, 64)\nshape 4:- (5851, 64, 64)\nnormalized_images shape:- (5949, 64)\nshape 1:- (5949, 64, 64)\nshape 2:- (5949, 64, 64)\nshape 3:- (5949, 64, 64)\nshape 4:- (5949, 64, 64)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x200 with 10 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"normalized_Hermitian_Digit_matrices shape:- torch.Size([60000, 64, 64])\nnormalized_hermitian_matrices_test_input shape:- torch.Size([10000, 64, 64])\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom torch.utils.data import DataLoader, TensorDataset\n\nclass MatrixModel(nn.Module):\n  def __init__(self,num_classes = 10, matrix_size = 64):\n    super().__init__()\n    self.num_classes = num_classes\n    self.matrix_size = matrix_size\n    self.eigenvalues = nn.Parameter(torch.randn(num_classes,matrix_size,dtype = torch.float64))\n    self.eigenvectors_real = nn.Parameter(torch.randn(num_classes,matrix_size,matrix_size,dtype = torch.float64))\n    self.eigenvectors_imag = nn.Parameter(torch.randn(num_classes,matrix_size,matrix_size,dtype = torch.float64))\n\n  def get_complex_eigenvectors(self):\n    return torch.complex(self.eigenvectors_real, self.eigenvectors_imag)\n\n  def find_unitary_transformation(self,input_density_matrix, output_density_matrix):\n    X = np.dot(output_density_matrix, np.linalg.pinv(input_density_matrix))\n    U, S, V_dagger = np.linalg.svd(X, full_matrices=False)\n    phase_matrix = np.diag(np.exp(1j * np.angle(S)))\n    unitary_matrix = U @ (phase_matrix @ V_dagger)\n    unitary_matrix /= np.linalg.det(unitary_matrix)**(1/2)\n    return unitary_matrix\n\n  def is_unitary(matrix):\n    # Check if the matrix is unitary\n    identity = np.eye(matrix.shape[0])\n    return np.allclose(matrix @ matrix.conj().T, identity) and np.allclose(matrix.conj().T @ matrix, identity)\n\n\n    \n  def make_unitary1(self,matrix):\n    U,_,Vh = torch.linalg.svd(matrix,full_matrices = False)\n    return U @ Vh\n\n  def make_unitary2(self,matrix):\n    matrix = matrix / (torch.linalg.norm(matrix) + 1e-12) #for -i log(V) case only\n    Q,R = torch.linalg.qr(matrix)\n    return Q\n\n  def make_unitary3(self,matrix):\n    # Lower triangular density matrix\n    matrix = matrix.detach().cpu().numpy()\n    input_density_matrix = np.zeros((64, 64), dtype=np.complex128)\n    input_density_matrix[0, 0] = 1.0\n    lower_triangular = np.tril(matrix)\n    lower_triangular_conj = np.conj(lower_triangular).T\n    Density_Matrix_Classical_Lower = lower_triangular + lower_triangular_conj\n\n  def make_unitary4(self, matrix):\n    U, P = torch.linalg.polar(matrix)  # U is unitary\n    return U\n\n\n    # Upper triangular density matrix\n    upper_triangular = np.triu(matrix)\n    upper_triangular_conj = np.conj(upper_triangular).T\n    Density_Matrix_Classical_Upper = upper_triangular + upper_triangular_conj\n\n    # Halve diagonal elements\n    np.fill_diagonal(Density_Matrix_Classical_Lower,\n                     Density_Matrix_Classical_Lower.diagonal() / 2)\n    np.fill_diagonal(Density_Matrix_Classical_Upper,\n                     Density_Matrix_Classical_Upper.diagonal() / 2)\n\n    # Normalize by trace\n    Density_Matrix_Classical_Lower_Normalized = (\n        Density_Matrix_Classical_Lower / np.trace(Density_Matrix_Classical_Lower)\n    )\n    Density_Matrix_Classical_Upper_Normalized = (\n        Density_Matrix_Classical_Upper / np.trace(Density_Matrix_Classical_Upper)\n    )\n\n    # Find unitary transformations\n    unitary_transformation_lower = self.find_unitary_transformation(\n        input_density_matrix, Density_Matrix_Classical_Lower_Normalized\n    )\n    unitary_transformation_upper = self.find_unitary_transformation(\n        input_density_matrix, Density_Matrix_Classical_Upper_Normalized\n    )\n\n    # Choose one — here we return the lower version\n    # return unitary_transformation_lower\n    return torch.from_numpy(unitary_transformation_lower).to(torch.complex128)\n  \n\n    \n      \n\n  \n  def get_hamiltonians_orig1(self):\n        eigenvectors_complex = self.get_complex_eigenvectors()\n        unitary_vecs = torch.stack([self.make_unitary1(mat) for mat in eigenvectors_complex])\n        diag_matrices = torch.diag_embed(self.eigenvalues.to(torch.complex128))\n        hamiltonians = unitary_vecs @ diag_matrices @ unitary_vecs.conj().transpose(-1, -2)\n        hamiltonians = (hamiltonians + hamiltonians.conj().transpose(-1, -2)) / 2\n        return hamiltonians\n  \n  def get_hamiltonians_orig2(self):\n        eigenvectors_complex = self.get_complex_eigenvectors()\n        unitary_vecs = torch.stack([self.make_unitary2(mat) for mat in eigenvectors_complex])\n        diag_matrices = torch.diag_embed(self.eigenvalues.to(torch.complex128))\n        hamiltonians = unitary_vecs @ diag_matrices @ unitary_vecs.conj().transpose(-1, -2)\n        hamiltonians = (hamiltonians + hamiltonians.conj().transpose(-1, -2)) / 2\n        return hamiltonians\n  \n  def get_hamiltonians_orig3(self):\n        eigenvectors_complex = self.get_complex_eigenvectors()\n        unitary_vecs = torch.stack([self.make_unitary3(mat) for mat in eigenvectors_complex])\n        diag_matrices = torch.diag_embed(self.eigenvalues.to(torch.complex128))\n        hamiltonians = unitary_vecs @ diag_matrices @ unitary_vecs.conj().transpose(-1, -2)\n        hamiltonians = (hamiltonians + hamiltonians.conj().transpose(-1, -2)) / 2\n      \n        return hamiltonians\n\n    \n\n\n\n  def forward(self):\n    return self.get_hamiltonians_orig2() #OR get_hamiltonians_orig2,get_hamiltonians_orig3\n\ndef combined_loss_batched(output, target_batch, labels_batch):\n  batch_size = target_batch.size(0)\n  class_hamiltonians = output[labels_batch]\n  # print(class_hamiltonians.shape)\n  # print(target_batch.shape)\n  # diff = torch.nan_to_num(class_hamiltonians - target_batch,nan = 0.0,posinf = 1e6,neginf = -1e6)\n  # losses = torch.linalg.norm(diff,dim = (1,2))  \n  losses = torch.linalg.norm(class_hamiltonians - target_batch,dim = (1,2))\n  return torch.mean(losses)\n\ndef combined_loss_batched2(output, target_batch, labels_batch):\n    batch_size = target_batch.size(0)\n\n    # Differentiable class selection\n    class_hamiltonians = torch.gather(\n        output, 1, labels_batch.view(-1, 1, 1, 1).expand(-1, 1, 64, 64)\n    ).squeeze(1)\n\n    # Convert target to Hamiltonian form\n    target_batch = target_batch.reshape(batch_size, -1)  # (n, 64)\n    target_batch = torch.einsum('bi,bj->bij', target_batch, target_batch.conj())  # (n, 64, 64)\n\n    losses = torch.linalg.norm(class_hamiltonians - target_batch, dim=(1, 2))\n    return torch.mean(losses)\n\n\ndef create_labels_from_class_counts(class_counts):\n    labels = []\n    for class_idx, count in enumerate(class_counts):\n        labels.extend([class_idx] * count)\n    return labels\n\ndef create_batched_data(data, labels, batch_size=64):\n    if not isinstance(data, torch.Tensor):\n        if isinstance(data, list) and len(data) > 0:\n            data = torch.stack(data)\n        else:\n            data = torch.tensor(data)\n    if not isinstance(labels, torch.Tensor):\n        labels = torch.tensor(labels)\n    if not data.dtype == torch.complex128:\n        data = data.to(torch.complex128)\n    dataset = TensorDataset(data, labels)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    return dataloader\n\ndef train_model(model, dataloader,optimizer, scheduler, threshold = 0.0000001, num_epochs=100):\n    model.train()\n    all_losses = []\n    wait = 0\n    patience = 5\n    to_stop = 0\n    epoch = 0\n    for epoch in range(num_epochs):\n        print(f\"Epoch:- {epoch}\")\n        total_loss = 0.0\n        num_batches = 0\n\n        for batch_data, batch_labels in dataloader:\n            if num_batches % 1000 == 0:\n              print(num_batches)\n            batch_data = batch_data.to(device)\n            batch_labels = batch_labels.to(device)\n            optimizer.zero_grad()\n            outputs = model()\n            loss = combined_loss_batched(outputs, batch_data, batch_labels)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            num_batches += 1\n\n        avg_loss = total_loss / num_batches\n        scheduler.step(avg_loss)\n        diff = 0\n        if epoch > 2:\n          diff = all_losses[-1] - avg_loss\n        all_losses.append(avg_loss)\n        if epoch > 2 and avg_loss - all_losses[-1] < threshold:\n          print(\"less than threshold\")\n          if wait < patience:\n            wait = wait + 1\n          else:\n            to_stop = 1\n        if epoch % 1 == 0:\n            print(f'Epoch [{epoch}/{num_epochs}], Average Loss: {avg_loss:.4e}, Difference = {diff:.10e}')\n        epoch = epoch + 1\n\n    print(\"Training completed!\")\n\ndef inference(model, test_data, test_labels=None):\n    model.eval()\n\n    with torch.no_grad():\n        hamiltonians = model().cpu() # 10,64,64\n        # print(hamiltonians.shape)\n        predicted_labels = []\n\n        for test_sample in test_data:\n            if isinstance(test_sample, torch.Tensor):\n                test_sample = test_sample.cpu()\n            frobenius_norms = []\n            for class_idx in range(10):\n                # print(test_sample.shape)\n                # print(hamiltonians[class_idx].shape)\n                norm = torch.linalg.norm(test_sample - hamiltonians[class_idx], ord='fro')\n                frobenius_norms.append(norm.item())\n            predicted_labels.append(np.argmin(frobenius_norms))\n        if test_labels is not None:\n            accuracy = np.sum(np.array(predicted_labels) == np.array(test_labels))\n            accuracy_percent = (accuracy / len(test_labels)) * 100\n            return predicted_labels, accuracy_percent\n\n        return predicted_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T05:08:08.663975Z","iopub.execute_input":"2025-08-13T05:08:08.664275Z","iopub.status.idle":"2025-08-13T05:08:08.697203Z","shell.execute_reply.started":"2025-08-13T05:08:08.664255Z","shell.execute_reply":"2025-08-13T05:08:08.696286Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import scipy\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(\"Creating the training data and labels\")\nclass_counts = [5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]\n# class_counts = [100] * 10\ntraining_labels = create_labels_from_class_counts(class_counts)\ntraining_data = torch.as_tensor(normalized_Hermitian_Digit_matrices,dtype = torch.complex128,device = device)\nprint(f\"training data shape:- {training_data.shape}\")\n# training_data_small = torch.as_tensor(normalized_Hermitian_Digit_matrices_small.view(-1,8,8))\n# print(f\"training data small shape:- {training_data_small.shape}\")\n\n\nprint(\"Initialising the model,optimier,scheduler\")\nmodel = MatrixModel(num_classes = 10,matrix_size = 64).to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=10)\nbatch_size = 15\n\ndataloader = create_batched_data(training_data, training_labels, batch_size=batch_size)\n# dataloader_small = create_batched_data(training_data_small,training_labels,batch_size = batch_size)\n\nprint(f\"Training with {len(dataloader)} batches of size {batch_size}\")\ntrain_model(model, dataloader, optimizer, scheduler,num_epochs = 15)\n\nmodel.eval()\nwith torch.no_grad():\n  trained_hamiltonians = model().cpu()\n  trained_eigenvalues = model.eigenvalues.cpu()\n  trained_eigenvectors = model.get_complex_eigenvectors().cpu()\n\n  print(\"\\nTrained Components:\")\n  for class_idx in range(10):\n      print(f\"\\nClass {class_idx}:\")\n      print(f\"Eigenvalues shape: {trained_eigenvalues[class_idx].shape}\")\n      print(f\"Eigenvectors shape: {trained_eigenvectors[class_idx].shape}\")\n      print(f\"Hamiltonian shape: {trained_hamiltonians[class_idx].shape}\")\n      H = trained_hamiltonians[class_idx]\n      hermitian_error = torch.max(torch.abs(H - H.conj().T))\n      print(f\"Hermiticity error: {hermitian_error:.2e}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T05:08:12.500732Z","iopub.execute_input":"2025-08-13T05:08:12.501192Z","iopub.status.idle":"2025-08-13T05:11:19.554759Z","shell.execute_reply.started":"2025-08-13T05:08:12.501046Z","shell.execute_reply":"2025-08-13T05:11:19.553353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Performing inference..\")\ntrain_data = torch.as_tensor(normalized_Hermitian_Digit_matrices,dtype = torch.complex128)\n\ntrain_target = [0]*100 + [1]*100 + [2]*100 + [3]*100 + [4]*100 + [5]*100 + [6]*100 + [7]*100 + [8]*100 + [9]*100\n\ntest_data = torch.as_tensor(normalized_hermitian_matrices_test_input,\n                               dtype=torch.complex128)\ntest_target = [0]*20 + [1]*20 + [2]*20 + [3]*20 + [4]*20 + [5]*20 + [6]*20 + [7]*20 + [8]*20 + [9]*20\n\npredicted_labels , train_acc = inference(model,train_data,torch.tensor(training_labels,dtype = torch.long))\nprint(f\"Train Accuracy: {train_acc:.2f}%\")\n\npredicted_labels, accuracy = inference(model, test_data, torch.tensor(y_test,dtype = torch.long))\nprint(f\"Test Accuracy: {accuracy:.2f}%\")\n\ndef visualize_eigenvalues(model):\n    with torch.no_grad():\n        plt.figure(figsize=(15,6))\n        for c in range(10):\n            eig = model.eigenvalues[c].cpu().numpy()\n            plt.subplot(2,5,c+1)\n            plt.plot(np.sort(eig), 'o--')\n            plt.title(f'Class {c}')\n            plt.grid(True)\n        plt.tight_layout()\n        plt.show()\n\nvisualize_eigenvalues(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:05:32.561331Z","iopub.execute_input":"2025-08-12T16:05:32.561707Z","iopub.status.idle":"2025-08-12T16:07:14.879150Z","shell.execute_reply.started":"2025-08-12T16:05:32.561674Z","shell.execute_reply":"2025-08-12T16:07:14.877891Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Approach 2:","metadata":{}},{"cell_type":"code","source":"# Trainable Mean Hamiltonians of the 10 classes , and then fixing the eigen vectors for each train hamiltonian as mean hamiltonian for that class\n# then training the eigen values for each train data to minimize the frobenius norm between the actual train hamiltonian and the reconstructed hamiltonian\n# this is the new representation of the train hamiltonian using the Adiabatic Theorem , i.e. perturbing only the eigen values within class and keeping the\n# eigen vectors that class found from the whole data in that class as constant in the new representation of the particular hamiltonian\n\n# For Inference we use all the 10 eigen vectors obtained from the train data\n# and keep the eigen value matrix as trainable per test hamitonian , to get 10,64,64, hamiltonian representation\n# of the test data , and then selecting the class that gives the minimum reconstruction error as the class of the test hamiltonian m\n# also instead of this KNN can be used between the 10,64,64 and the reconstructed train hamiltonians per class , and select the class from the list \n# of the forbenius norm per class by majority vote , i.e the class that produce the least KNN formbenius norms...\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\nclass_sizes = [5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]  # Must sum to 60000\n\nclass ComplexMatrixModel(nn.Module):\n    def __init__(self, num_classes=10, matrix_size=64):\n        super().__init__()\n        self.num_classes = num_classes\n        self.matrix_size = matrix_size\n        self.class_sizes = class_sizes\n        self.eigenvectors = nn.Parameter(\n            torch.randn(num_classes, matrix_size, matrix_size, dtype=torch.complex128, device=device)\n        )\n        self.eigenvalues = nn.Parameter(\n            torch.randn(num_classes, matrix_size, dtype=torch.float64, device=device)\n        )\n        self.class_weights = nn.ParameterList([\n            nn.Parameter(torch.randn(size, matrix_size, dtype=torch.float64, device=device))\n            for size in self.class_sizes\n        ])\n\n    def make_unitary1(self, matrix):\n        U, _, Vh = torch.linalg.svd(matrix)\n        return U @ Vh\n\n    def make_unitary2(self,matrix):\n      Q,R = torch.linalg.qr(matrix)\n      return Q\n\n    def make_unitary3(self,matrix):\n      matrix = (matrix + matrix.conj().T) / 2\n      s = torch.matrix_exp((-1j)*matrix)\n      return s\n\n    #CHange 1,2,3\n    def forward(self, class_idx=None, batch_indices=None):\n        if class_idx is not None:\n            return self._generate_class_hamiltonians1(class_idx, batch_indices)\n        else:\n            all_hams = []\n            for idx in range(self.num_classes):\n                hams = self._generate_class_hamiltonians1(idx)\n                all_hams.append(hams)\n            return torch.cat(all_hams, dim=0)\n\n    def _generate_class_hamiltonians1(self, class_idx, batch_indices=None):\n        U = self.make_unitary1(self.eigenvectors[class_idx]) \n        eigvals = self.eigenvalues[class_idx]               \n        if batch_indices is not None:\n            weights = self.class_weights[class_idx][batch_indices]  \n        else:\n            weights = self.class_weights[class_idx]   \n\n        scaled_eig = weights * eigvals.unsqueeze(0)        \n        diag_mats = torch.diag_embed(scaled_eig).to(torch.complex128)  \n        U = U.to(torch.complex128)\n        U_expanded = U.unsqueeze(0).expand(diag_mats.shape[0], -1, -1) \n        U_conj_T = U_expanded.conj().transpose(-1, -2)               \n        H = U_expanded @ diag_mats @ U_conj_T                  \n        H_hermitian = (H + H.conj().transpose(-1, -2)) / 2\n        return H_hermitian\n\n    def _generate_class_hamiltonians2(self, class_idx, batch_indices=None):\n        U = self.make_unitary2(self.eigenvectors[class_idx]) \n        eigvals = self.eigenvalues[class_idx]               \n        if batch_indices is not None:\n            weights = self.class_weights[class_idx][batch_indices]  \n        else:\n            weights = self.class_weights[class_idx]   \n\n        scaled_eig = weights * eigvals.unsqueeze(0)        \n        diag_mats = torch.diag_embed(scaled_eig).to(torch.complex128)  \n        U = U.to(torch.complex128)\n        U_expanded = U.unsqueeze(0).expand(diag_mats.shape[0], -1, -1) \n        U_conj_T = U_expanded.conj().transpose(-1, -2)               \n        H = U_expanded @ diag_mats @ U_conj_T                  \n        H_hermitian = (H + H.conj().transpose(-1, -2)) / 2\n        return H_hermitian\n\n    def _generate_class_hamiltonians3(self, class_idx, batch_indices=None):\n        U = self.make_unitary3(self.eigenvectors[class_idx]) \n        eigvals = self.eigenvalues[class_idx]               \n        if batch_indices is not None:\n            weights = self.class_weights[class_idx][batch_indices]  \n        else:\n            weights = self.class_weights[class_idx]   \n\n        scaled_eig = weights * eigvals.unsqueeze(0)        \n        diag_mats = torch.diag_embed(scaled_eig).to(torch.complex128)  \n        U = U.to(torch.complex128)\n        U_expanded = U.unsqueeze(0).expand(diag_mats.shape[0], -1, -1) \n        U_conj_T = U_expanded.conj().transpose(-1, -2)               \n        H = U_expanded @ diag_mats @ U_conj_T                  \n        H_hermitian = (H + H.conj().transpose(-1, -2)) / 2\n        return H_hermitian\n\n    \n    def reconstruct_hamiltonian1(self, class_idx, eigenvalues):\n        U = self.make_unitary1(self.eigenvectors[class_idx]).to(torch.complex128)\n        d = torch.diag(eigenvalues.to(torch.complex128))\n        H = U @ d @ U.conj().T\n        H_hermitian = (H + H.conj().T)/2\n        return H_hermitian\n\n    def reconstruct_hamiltonian2(self, class_idx, eigenvalues):\n        U = self.make_unitary2(self.eigenvectors[class_idx]).to(torch.complex128)\n        d = torch.diag(eigenvalues.to(torch.complex128))\n        H = U @ d @ U.conj().T\n        H_hermitian = (H + H.conj().T)/2\n        return H_hermitian\n\n    def reconstruct_hamiltonian3(self, class_idx, eigenvalues):\n        U = self.make_unitary3(self.eigenvectors[class_idx]).to(torch.complex128)\n        d = torch.diag(eigenvalues.to(torch.complex128))\n        H = U @ d @ U.conj().T\n        H_hermitian = (H + H.conj().T)/2\n        return H_hermitian\n\ndef frobenius_loss(output, target):\n    return torch.mean(torch.linalg.norm(output - target, dim=(-2, -1)))\n\ndef train_model_batched(model, train_data, train_labels, epochs=10, batch_size=256):\n    model.train()\n    optimizer = optim.Adam(model.parameters(), lr=1e-2)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=10)\n\n    train_data = torch.as_tensor(train_data, dtype=torch.complex128)\n    train_labels = torch.as_tensor(train_labels, dtype=torch.long)\n\n    train_dataset = TensorDataset(train_data, train_labels)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    for epoch in range(epochs):\n        total_loss = 0\n        batch_count = 0\n        for batch_data, batch_labels in train_loader:\n            if batch_count % 1000 == 0 :\n                print(f\"Batch:{batch_count}\")\n            optimizer.zero_grad()\n            batch_outputs, batch_targets = [], []\n            for class_idx in range(10):\n                mask = (batch_labels == class_idx)\n                if not mask.any():\n                    continue\n                sample_idx = torch.where(mask)[0]\n                class_sample_idxs = batch_data.new_tensor(\n                    [idx.item() for idx in sample_idx], dtype=torch.long, device=device\n                )\n                class_local_indices = mask.nonzero().flatten()\n                class_out = model(class_idx=class_idx, batch_indices=class_local_indices)\n                batch_outputs.append(class_out)\n                batch_targets.append(batch_data[mask].to(torch.complex128))\n\n            if batch_outputs:\n                outputs = torch.cat(batch_outputs, dim=0)\n                targets = torch.cat(batch_targets, dim=0)\n                loss = frobenius_loss(outputs, targets)\n                loss.backward()\n                optimizer.step()\n                total_loss += loss.item()\n                batch_count += 1\n        avg_loss = total_loss / max(batch_count, 1)\n        scheduler.step(avg_loss)\n        if epoch % 1 == 0:\n            print(f\"Epoch [{epoch+1}/{epochs}] Loss: {avg_loss:.5e}\")\n\n#Here change 1,2,3    \ndef classify_test(model, test_hamiltonians, test_labels, optimize_epochs=20, lr=0.1):\n    model.eval()\n    results = []\n    with torch.no_grad():\n        fixed_eigenvecs = []\n        for c in range(10):\n            fixed_eigenvecs.append(model.make_unitary1(model.eigenvectors[c]).to(torch.complex128))\n\n    for idx, test_H in enumerate(test_hamiltonians):\n        min_error = float('inf')\n        best_class = -1\n        test_H = test_H.to(device).to(torch.complex128)\n        for class_idx in range(10):\n            # Optimize eigenvalues for this test_H and class\n            eigvals = model.eigenvalues[class_idx].detach().clone().to(device).requires_grad_(True)\n            optimizer = optim.Adam([eigvals], lr=lr)\n            for _ in range(optimize_epochs):\n                optimizer.zero_grad()\n                U = fixed_eigenvecs[class_idx]\n                dmat = torch.diag(eigvals.to(torch.complex128))\n                H = U @ dmat @ U.conj().T\n                H_herm = (H + H.conj().T)/2\n                loss = torch.linalg.norm(H_herm - test_H)\n                loss.backward()\n                optimizer.step()\n            err = loss.item()\n            if err < min_error:\n                min_error = err\n                best_class = class_idx\n        results.append(best_class)\n        if (idx+1)%50 == 0 or idx < 10:\n            print(f\"Test {idx+1}/{len(test_hamiltonians)} done, best class: {best_class}, loss: {min_error:.3e}\")\n    return np.array(results)\n\ndef evaluate(pred_labels, true_labels):\n    acc = (pred_labels == true_labels.cpu().numpy()).mean()\n    print(f\"\\nTest Accuracy: {acc*100:.2f}%\")\n    for c in range(10):\n        mask = (true_labels.cpu().numpy() == c)\n        acc_c = (pred_labels[mask] == c).mean() if mask.sum() > 0 else np.nan\n        print(f\"Class {c}: {acc_c*100:.2f}% ({mask.sum()} samples)\")\n    return acc\n\ndef visualize_eigenvalues(model):\n    with torch.no_grad():\n        plt.figure(figsize=(15,6))\n        for c in range(10):\n            eig = model.eigenvalues[c].cpu().numpy()\n            plt.subplot(2,5,c+1)\n            plt.plot(np.sort(eig), 'o--')\n            plt.title(f'Class {c}')\n            plt.grid(True)\n        plt.tight_layout()\n        plt.show()\n\n# Here instead of Classify Test , KNN can also be used from the train new represented (Trained Eigen Values) Hamitonians and the test new represented Hamiltonians (Trained Eigen Values) per class\ndef classify_test_knn_eig(model, train_data, train_labels, test_data, case , k=3):\n    device = next(model.parameters()).device\n    \n    # Function to get \"new represented\" Hamiltonians from trained eigenvalues\n    def get_represented_hamiltonians(data, labels):\n        represented = []\n        for i in range(len(data)):\n            if i%1000 == 0 :\n                print(i)\n            cls = labels[i].item()\n            if case == 1:\n              U = model.make_unitary1(model.eigenvectors[cls]).to(torch.complex128).to(device)\n            elif case == 2:\n              U = model.make_unitary2(model.eigenvectors[cls]).to(torch.complex128).to(device)\n            else:\n              U = model.make_unitary3(model.eigenvectors[cls]).to(torch.complex128).to(device)\n            eigvals = model.eigenvalues[cls].detach().to(torch.complex128).to(device)\n            H = U @ torch.diag(eigvals) @ U.conj().T\n            H = (H + H.conj().T) / 2\n            represented.append(H)\n        represented = torch.stack(represented)\n        return represented\n\n    # Generate represented Hamiltonians\n    print(\"geting represented hamiltonians for training\")\n    train_repr = get_represented_hamiltonians(train_data, train_labels)\n    print(\"geting represented hamiltonians for testing\")\n    test_repr = get_represented_hamiltonians(test_data, torch.zeros(len(test_data), dtype=torch.long))\n\n    # Flatten to vectors for KNN\n    X_train = train_repr.reshape(len(train_repr), -1).real.cpu().numpy()\n    X_test = test_repr.reshape(len(test_repr), -1).real.cpu().numpy()\n    y_train = train_labels.cpu().numpy()\n\n    # Fit KNN\n    print(\"training the KNN model....\")\n    knn = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n    knn.fit(X_train, y_train)\n\n    # Predict\n    print(\"Predicting....\")\n    predictions = knn.predict(X_test)\n    return predictions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T08:37:25.515950Z","iopub.execute_input":"2025-08-13T08:37:25.516397Z","iopub.status.idle":"2025-08-13T08:37:25.564142Z","shell.execute_reply.started":"2025-08-13T08:37:25.516370Z","shell.execute_reply":"2025-08-13T08:37:25.562775Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"def create_labels_from_class_counts(class_counts):\n    labels = []\n    for class_idx, count in enumerate(class_counts):\n        labels.extend([class_idx] * count)\n    return labels\n\ndef create_batched_data(data, labels, batch_size=64):\n    if not isinstance(data, torch.Tensor):\n        if isinstance(data, list) and len(data) > 0:\n            data = torch.stack(data)\n        else:\n            data = torch.tensor(data)\n    if not isinstance(labels, torch.Tensor):\n        labels = torch.tensor(labels)\n    if not data.dtype == torch.complex128:\n        data = data.to(torch.complex128)\n    dataset = TensorDataset(data, labels)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    \n    return dataloader\n\n\nclass_counts = [5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]\ntrain_hamiltonians = normalized_Hermitian_Digit_matrices\ntrain_labels = create_labels_from_class_counts(class_counts)\ntest_hamiltonians = normalized_hermitian_matrices_test_input\ntest_labels = y_test\n\nmodel = ComplexMatrixModel(num_classes=10, matrix_size=64).to(device)\nprint(\"Model Instantiated.\")\n\nprint(\"----- TRAINING PHASE -----\")\ntrain_model_batched(model, train_hamiltonians, np.array(train_labels), epochs=10, batch_size=15)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T07:37:00.563159Z","iopub.execute_input":"2025-08-13T07:37:00.564166Z","iopub.status.idle":"2025-08-13T08:27:47.332968Z","shell.execute_reply.started":"2025-08-13T07:37:00.564135Z","shell.execute_reply":"2025-08-13T08:27:47.330145Z"}},"outputs":[{"name":"stdout","text":"Model Instantiated.\n----- TRAINING PHASE -----\nBatch:0\nBatch:1000\nBatch:2000\nBatch:3000\nEpoch [1/10] Loss: 8.30120e-01\nBatch:0\nBatch:1000\nBatch:2000\nBatch:3000\nEpoch [2/10] Loss: 6.27858e-01\nBatch:0\nBatch:1000\nBatch:2000\nBatch:3000\nEpoch [3/10] Loss: 6.25574e-01\nBatch:0\nBatch:1000\nBatch:2000\nBatch:3000\nEpoch [4/10] Loss: 6.24485e-01\nBatch:0\nBatch:1000\nBatch:2000\nBatch:3000\nEpoch [5/10] Loss: 6.23818e-01\nBatch:0\nBatch:1000\nBatch:2000\nBatch:3000\nEpoch [6/10] Loss: 6.23526e-01\nBatch:0\nBatch:1000\nBatch:2000\nBatch:3000\nEpoch [7/10] Loss: 6.23156e-01\nBatch:0\nBatch:1000\nBatch:2000\nBatch:3000\nEpoch [8/10] Loss: 6.22958e-01\nBatch:0\nBatch:1000\nBatch:2000\nBatch:3000\nEpoch [9/10] Loss: 6.22751e-01\nBatch:0\nBatch:1000\nBatch:2000\nBatch:3000\nEpoch [10/10] Loss: 6.22537e-01\n----- CLASSIFICATION ON TEST -----\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2503828683.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----- CLASSIFICATION ON TEST -----\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mpred_labels_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_hamiltonians\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimize_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mpred_labels_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_hamiltonians\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/1014709846.py\u001b[0m in \u001b[0;36mclassify_test\u001b[0;34m(model, test_hamiltonians, test_labels, optimize_epochs, lr)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mfixed_eigenvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mfixed_eigenvecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_unitary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigenvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_H\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_hamiltonians\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         )\n","\u001b[0;31mAttributeError\u001b[0m: 'ComplexMatrixModel' object has no attribute 'make_unitary'"],"ename":"AttributeError","evalue":"'ComplexMatrixModel' object has no attribute 'make_unitary'","output_type":"error"}],"execution_count":16},{"cell_type":"code","source":"print(\"----- CLASSIFICATION ON TEST -----\")\n# pred_labels_train = classify_test(model,train_hamiltonians,torch.tensor(train_labels,dtype = torch.long),optimize_epochs=100,lr = 0.1)\n# pred_labels_test = classify_test(model, test_hamiltonians, torch.tensor(test_labels,dtype = torch.long), optimize_epochs=100, lr=0.1)  \npred_labels_test = classify_test_knn_eig(model,torch.tensor(train_hamiltonians,dtype = torch.complex128),torch.tensor(train_labels,dtype = torch.long) ,torch.tensor(test_hamiltonians,dtype = torch.complex128),1,k=3)\n\nprint(\"----- ACCURACY -----\")\ntrain_accuracy = evaluate(pred_labels_train, torch.tensor(train_labels,dtype = torch.long))\ntest_accuracy = evaluate(pred_labels_test, torch.tensor(test_labels,dtype = torch.long))\nprint(f\"Train accuracy: {train_accuracy}\")\nprint(f\"Test accuracy: {test_accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T08:39:37.207786Z","iopub.execute_input":"2025-08-13T08:39:37.210449Z"}},"outputs":[{"name":"stdout","text":"----- CLASSIFICATION ON TEST -----\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3915344982.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  pred_labels_test = classify_test_knn_eig(model,torch.tensor(train_hamiltonians,dtype = torch.complex128),torch.tensor(train_labels,dtype = torch.long) ,torch.tensor(test_hamiltonians,dtype = torch.complex128),1,k=3)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}